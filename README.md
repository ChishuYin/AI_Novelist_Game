# gpt2-finetune-novel
Finetuned GPT2 model on custom novel dataset
# GPT2-Chinese Novel Generator (LoRA Fine-Tuned)

This project fine-tunes a Chinese GPT2 model using a custom dataset of Chinese fiction, leveraging LoRA (Low-Rank Adaptation) for efficient training. The final model is capable of generating creative novel-style text in Chinese.

## ğŸ”§ Model Configuration

- **Base model**: [`uer/gpt2-chinese-cluecorpussmall`](https://huggingface.co/uer/gpt2-chinese-cluecorpussmall)
- **LoRA adapter path**: `outputs/gpt2_chinese_lora_small`
- **Tokenizer**: Loaded from the LoRA path, with `use_fast=False` to avoid Chinese tokenization issues.

## ğŸ—ï¸ How It Works

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import torch

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained("outputs/gpt2_chinese_lora_small", use_fast=False)

# Load base model + LoRA adapter
base_model = "uer/gpt2-chinese-cluecorpussmall"
model = AutoModelForCausalLM.from_pretrained(base_model)
model = PeftModel.from_pretrained(model, "outputs/gpt2_chinese_lora_small")
model.eval()

# Text generation function
def generate(text, max_tokens=50):
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            do_sample=True,
            top_p=0.99,
            temperature=0.95
        )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Example usage
if __name__ == "__main__":
    prompt = "å¥¹ç«™åœ¨æ¡¥å¤´ï¼Œæœ›ç€é›¨é›¾ä¸­çš„åŸå¢™ï¼Œå¿ƒé‡Œå¿½ç„¶æ³›èµ·ä¸€ç§å¥‡æ€ªçš„æƒ…ç»ªã€‚"
    output = generate(prompt)
    print("ğŸ“œ Output:\n", output)

# Output
ğŸ“œ ç”Ÿæˆå†…å®¹ï¼š
 å¥¹ ç«™ åœ¨ æ¡¥ å¤´ ï¼Œ æœ› ç€ é›¨ é›¾ ä¸­ çš„ åŸ å¢™ ï¼Œ å¿ƒ é‡Œ å¿½ ç„¶ æ³› èµ· ä¸€ ç§ å¥‡ æ€ª çš„ æƒ… ç»ª ã€‚ ä¸Š å®˜ å©‰ å„¿ æ˜¯ å¦‚ ä½• å› è½¬ ç€ èµ° æ¥ çš„ ï¼Ÿ æ˜¯ è° å·² ç» èµ° äº† å¤š å°‘ æ­¥ ï¼Ÿ ä»– åœ¨ æ¡¥ ä¸Š åˆ æ˜¯ èµ° äº† å¤š å°‘ æ­¥ ï¼Ÿ é‚£ äº› äºº éƒ½ ç«™ åœ¨ å“ª é‡Œ ï¼Ÿ ä»– ä¸ å† æƒ³ èµ°

# Project structure
gpt2_novelist/
â”œâ”€â”€ outputs/                      # Contains fine-tuned LoRA model
â”œâ”€â”€ generate.py                  # Inference script
â”œâ”€â”€ train.py                     # (Optional) Training script
â”œâ”€â”€ data/                        # Custom dataset (not uploaded)
â””â”€â”€ README.md

# Requirements
pip install torch transformers peft

# Features
Supports Chinese text generation
LoRA for parameter-efficient fine-tuning
Sampling configuration with top_p and temperature for creative outputs

# TODO
Upload training script and dataset description
