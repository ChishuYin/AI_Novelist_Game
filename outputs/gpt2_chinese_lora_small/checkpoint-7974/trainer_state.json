{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 7974,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003762227238525207,
      "grad_norm": 0.8797474503517151,
      "learning_rate": 4.994356659142213e-05,
      "loss": 4.1816,
      "step": 10
    },
    {
      "epoch": 0.007524454477050414,
      "grad_norm": 1.1057285070419312,
      "learning_rate": 4.988086280411337e-05,
      "loss": 4.1654,
      "step": 20
    },
    {
      "epoch": 0.011286681715575621,
      "grad_norm": 1.3531596660614014,
      "learning_rate": 4.981815901680462e-05,
      "loss": 4.1925,
      "step": 30
    },
    {
      "epoch": 0.015048908954100828,
      "grad_norm": 1.3487998247146606,
      "learning_rate": 4.9755455229495864e-05,
      "loss": 4.0423,
      "step": 40
    },
    {
      "epoch": 0.018811136192626036,
      "grad_norm": 0.9875597953796387,
      "learning_rate": 4.969275144218711e-05,
      "loss": 3.9902,
      "step": 50
    },
    {
      "epoch": 0.022573363431151242,
      "grad_norm": 0.9644561409950256,
      "learning_rate": 4.963004765487836e-05,
      "loss": 3.839,
      "step": 60
    },
    {
      "epoch": 0.02633559066967645,
      "grad_norm": 0.9443587064743042,
      "learning_rate": 4.9567343867569607e-05,
      "loss": 3.8676,
      "step": 70
    },
    {
      "epoch": 0.030097817908201655,
      "grad_norm": 0.8132889866828918,
      "learning_rate": 4.950464008026085e-05,
      "loss": 3.8686,
      "step": 80
    },
    {
      "epoch": 0.033860045146726865,
      "grad_norm": 0.7872349619865417,
      "learning_rate": 4.9441936292952095e-05,
      "loss": 3.8224,
      "step": 90
    },
    {
      "epoch": 0.03762227238525207,
      "grad_norm": 0.8862143754959106,
      "learning_rate": 4.937923250564334e-05,
      "loss": 3.5945,
      "step": 100
    },
    {
      "epoch": 0.04138449962377728,
      "grad_norm": 0.7275510430335999,
      "learning_rate": 4.931652871833459e-05,
      "loss": 3.6715,
      "step": 110
    },
    {
      "epoch": 0.045146726862302484,
      "grad_norm": 0.653150737285614,
      "learning_rate": 4.925382493102584e-05,
      "loss": 3.721,
      "step": 120
    },
    {
      "epoch": 0.04890895410082769,
      "grad_norm": 0.6518679261207581,
      "learning_rate": 4.9191121143717085e-05,
      "loss": 3.6789,
      "step": 130
    },
    {
      "epoch": 0.0526711813393529,
      "grad_norm": 0.7727841734886169,
      "learning_rate": 4.912841735640833e-05,
      "loss": 3.7096,
      "step": 140
    },
    {
      "epoch": 0.056433408577878104,
      "grad_norm": 0.7331328988075256,
      "learning_rate": 4.906571356909957e-05,
      "loss": 3.7033,
      "step": 150
    },
    {
      "epoch": 0.06019563581640331,
      "grad_norm": 0.7079971432685852,
      "learning_rate": 4.900300978179082e-05,
      "loss": 3.7137,
      "step": 160
    },
    {
      "epoch": 0.06395786305492852,
      "grad_norm": 0.9006010293960571,
      "learning_rate": 4.894030599448207e-05,
      "loss": 3.6072,
      "step": 170
    },
    {
      "epoch": 0.06772009029345373,
      "grad_norm": 0.7114293575286865,
      "learning_rate": 4.8877602207173315e-05,
      "loss": 3.7337,
      "step": 180
    },
    {
      "epoch": 0.07148231753197894,
      "grad_norm": 0.6487343311309814,
      "learning_rate": 4.881489841986456e-05,
      "loss": 3.8171,
      "step": 190
    },
    {
      "epoch": 0.07524454477050414,
      "grad_norm": 0.8350045680999756,
      "learning_rate": 4.875219463255581e-05,
      "loss": 3.6496,
      "step": 200
    },
    {
      "epoch": 0.07900677200902935,
      "grad_norm": 0.8058483600616455,
      "learning_rate": 4.868949084524706e-05,
      "loss": 3.5931,
      "step": 210
    },
    {
      "epoch": 0.08276899924755456,
      "grad_norm": 0.6364076137542725,
      "learning_rate": 4.86267870579383e-05,
      "loss": 3.6874,
      "step": 220
    },
    {
      "epoch": 0.08653122648607976,
      "grad_norm": 0.8354154825210571,
      "learning_rate": 4.8564083270629546e-05,
      "loss": 3.5925,
      "step": 230
    },
    {
      "epoch": 0.09029345372460497,
      "grad_norm": 0.657339870929718,
      "learning_rate": 4.85013794833208e-05,
      "loss": 3.6599,
      "step": 240
    },
    {
      "epoch": 0.09405568096313018,
      "grad_norm": 0.5966843366622925,
      "learning_rate": 4.843867569601204e-05,
      "loss": 3.6341,
      "step": 250
    },
    {
      "epoch": 0.09781790820165538,
      "grad_norm": 0.6288737654685974,
      "learning_rate": 4.837597190870329e-05,
      "loss": 3.5942,
      "step": 260
    },
    {
      "epoch": 0.10158013544018059,
      "grad_norm": 0.6199781894683838,
      "learning_rate": 4.8313268121394536e-05,
      "loss": 3.7006,
      "step": 270
    },
    {
      "epoch": 0.1053423626787058,
      "grad_norm": 0.7803474068641663,
      "learning_rate": 4.8250564334085776e-05,
      "loss": 3.6905,
      "step": 280
    },
    {
      "epoch": 0.109104589917231,
      "grad_norm": 0.7172356247901917,
      "learning_rate": 4.8187860546777024e-05,
      "loss": 3.6722,
      "step": 290
    },
    {
      "epoch": 0.11286681715575621,
      "grad_norm": 0.7015440464019775,
      "learning_rate": 4.812515675946828e-05,
      "loss": 3.6339,
      "step": 300
    },
    {
      "epoch": 0.11662904439428141,
      "grad_norm": 0.6060841083526611,
      "learning_rate": 4.806245297215952e-05,
      "loss": 3.6674,
      "step": 310
    },
    {
      "epoch": 0.12039127163280662,
      "grad_norm": 0.6069166660308838,
      "learning_rate": 4.7999749184850766e-05,
      "loss": 3.5948,
      "step": 320
    },
    {
      "epoch": 0.12415349887133183,
      "grad_norm": 0.6251257658004761,
      "learning_rate": 4.7937045397542014e-05,
      "loss": 3.6003,
      "step": 330
    },
    {
      "epoch": 0.12791572610985705,
      "grad_norm": 0.8384507298469543,
      "learning_rate": 4.787434161023326e-05,
      "loss": 3.5677,
      "step": 340
    },
    {
      "epoch": 0.13167795334838225,
      "grad_norm": 0.5548399686813354,
      "learning_rate": 4.78116378229245e-05,
      "loss": 3.6394,
      "step": 350
    },
    {
      "epoch": 0.13544018058690746,
      "grad_norm": 0.6657395958900452,
      "learning_rate": 4.7748934035615756e-05,
      "loss": 3.6559,
      "step": 360
    },
    {
      "epoch": 0.13920240782543267,
      "grad_norm": 0.5962137579917908,
      "learning_rate": 4.7686230248307003e-05,
      "loss": 3.6225,
      "step": 370
    },
    {
      "epoch": 0.14296463506395787,
      "grad_norm": 0.8445164561271667,
      "learning_rate": 4.7623526460998244e-05,
      "loss": 3.6188,
      "step": 380
    },
    {
      "epoch": 0.14672686230248308,
      "grad_norm": 0.7170153260231018,
      "learning_rate": 4.756082267368949e-05,
      "loss": 3.5816,
      "step": 390
    },
    {
      "epoch": 0.1504890895410083,
      "grad_norm": 0.690537691116333,
      "learning_rate": 4.749811888638074e-05,
      "loss": 3.6723,
      "step": 400
    },
    {
      "epoch": 0.1542513167795335,
      "grad_norm": 0.6454122066497803,
      "learning_rate": 4.7435415099071986e-05,
      "loss": 3.6607,
      "step": 410
    },
    {
      "epoch": 0.1580135440180587,
      "grad_norm": 0.8192514181137085,
      "learning_rate": 4.7372711311763234e-05,
      "loss": 3.6672,
      "step": 420
    },
    {
      "epoch": 0.1617757712565839,
      "grad_norm": 0.6397294998168945,
      "learning_rate": 4.731000752445448e-05,
      "loss": 3.5892,
      "step": 430
    },
    {
      "epoch": 0.1655379984951091,
      "grad_norm": 1.2460416555404663,
      "learning_rate": 4.724730373714573e-05,
      "loss": 3.6144,
      "step": 440
    },
    {
      "epoch": 0.16930022573363432,
      "grad_norm": 0.690329372882843,
      "learning_rate": 4.718459994983697e-05,
      "loss": 3.6137,
      "step": 450
    },
    {
      "epoch": 0.17306245297215953,
      "grad_norm": 0.7028544545173645,
      "learning_rate": 4.712189616252822e-05,
      "loss": 3.622,
      "step": 460
    },
    {
      "epoch": 0.17682468021068473,
      "grad_norm": 0.8703952431678772,
      "learning_rate": 4.7059192375219465e-05,
      "loss": 3.6081,
      "step": 470
    },
    {
      "epoch": 0.18058690744920994,
      "grad_norm": 0.7512510418891907,
      "learning_rate": 4.699648858791071e-05,
      "loss": 3.6486,
      "step": 480
    },
    {
      "epoch": 0.18434913468773514,
      "grad_norm": 1.2152410745620728,
      "learning_rate": 4.693378480060196e-05,
      "loss": 3.6293,
      "step": 490
    },
    {
      "epoch": 0.18811136192626035,
      "grad_norm": 0.7455142736434937,
      "learning_rate": 4.687108101329321e-05,
      "loss": 3.6034,
      "step": 500
    },
    {
      "epoch": 0.19187358916478556,
      "grad_norm": 0.6764860153198242,
      "learning_rate": 4.6808377225984454e-05,
      "loss": 3.5717,
      "step": 510
    },
    {
      "epoch": 0.19563581640331076,
      "grad_norm": 0.7389270663261414,
      "learning_rate": 4.6745673438675695e-05,
      "loss": 3.6436,
      "step": 520
    },
    {
      "epoch": 0.19939804364183597,
      "grad_norm": 0.6911930441856384,
      "learning_rate": 4.668296965136694e-05,
      "loss": 3.5546,
      "step": 530
    },
    {
      "epoch": 0.20316027088036118,
      "grad_norm": 0.6861697435379028,
      "learning_rate": 4.66202658640582e-05,
      "loss": 3.5413,
      "step": 540
    },
    {
      "epoch": 0.20692249811888638,
      "grad_norm": 0.6756559610366821,
      "learning_rate": 4.655756207674944e-05,
      "loss": 3.6268,
      "step": 550
    },
    {
      "epoch": 0.2106847253574116,
      "grad_norm": 0.759145200252533,
      "learning_rate": 4.6494858289440685e-05,
      "loss": 3.6066,
      "step": 560
    },
    {
      "epoch": 0.2144469525959368,
      "grad_norm": 0.6430408358573914,
      "learning_rate": 4.643215450213193e-05,
      "loss": 3.6078,
      "step": 570
    },
    {
      "epoch": 0.218209179834462,
      "grad_norm": 0.8596550822257996,
      "learning_rate": 4.636945071482317e-05,
      "loss": 3.6041,
      "step": 580
    },
    {
      "epoch": 0.2219714070729872,
      "grad_norm": 0.775481641292572,
      "learning_rate": 4.630674692751442e-05,
      "loss": 3.5911,
      "step": 590
    },
    {
      "epoch": 0.22573363431151242,
      "grad_norm": 0.7406442165374756,
      "learning_rate": 4.6244043140205675e-05,
      "loss": 3.6027,
      "step": 600
    },
    {
      "epoch": 0.22949586155003762,
      "grad_norm": 0.8359267115592957,
      "learning_rate": 4.6181339352896915e-05,
      "loss": 3.5406,
      "step": 610
    },
    {
      "epoch": 0.23325808878856283,
      "grad_norm": 0.7772769331932068,
      "learning_rate": 4.611863556558816e-05,
      "loss": 3.6149,
      "step": 620
    },
    {
      "epoch": 0.23702031602708803,
      "grad_norm": 0.6679965853691101,
      "learning_rate": 4.605593177827941e-05,
      "loss": 3.5028,
      "step": 630
    },
    {
      "epoch": 0.24078254326561324,
      "grad_norm": 0.6721069812774658,
      "learning_rate": 4.599322799097066e-05,
      "loss": 3.6056,
      "step": 640
    },
    {
      "epoch": 0.24454477050413845,
      "grad_norm": 0.8109795451164246,
      "learning_rate": 4.59305242036619e-05,
      "loss": 3.5957,
      "step": 650
    },
    {
      "epoch": 0.24830699774266365,
      "grad_norm": 0.6415939927101135,
      "learning_rate": 4.586782041635315e-05,
      "loss": 3.6062,
      "step": 660
    },
    {
      "epoch": 0.2520692249811889,
      "grad_norm": 0.9513852596282959,
      "learning_rate": 4.58051166290444e-05,
      "loss": 3.5338,
      "step": 670
    },
    {
      "epoch": 0.2558314522197141,
      "grad_norm": 0.6901411414146423,
      "learning_rate": 4.574241284173564e-05,
      "loss": 3.5141,
      "step": 680
    },
    {
      "epoch": 0.2595936794582393,
      "grad_norm": 0.7413886189460754,
      "learning_rate": 4.567970905442689e-05,
      "loss": 3.6857,
      "step": 690
    },
    {
      "epoch": 0.2633559066967645,
      "grad_norm": 0.7994610071182251,
      "learning_rate": 4.5617005267118136e-05,
      "loss": 3.5923,
      "step": 700
    },
    {
      "epoch": 0.2671181339352897,
      "grad_norm": 0.8022361993789673,
      "learning_rate": 4.555430147980938e-05,
      "loss": 3.583,
      "step": 710
    },
    {
      "epoch": 0.2708803611738149,
      "grad_norm": 0.6552684307098389,
      "learning_rate": 4.549159769250063e-05,
      "loss": 3.5685,
      "step": 720
    },
    {
      "epoch": 0.2746425884123401,
      "grad_norm": 0.8856039047241211,
      "learning_rate": 4.542889390519188e-05,
      "loss": 3.5644,
      "step": 730
    },
    {
      "epoch": 0.27840481565086533,
      "grad_norm": 1.0983986854553223,
      "learning_rate": 4.5366190117883126e-05,
      "loss": 3.6502,
      "step": 740
    },
    {
      "epoch": 0.28216704288939054,
      "grad_norm": 0.7492310404777527,
      "learning_rate": 4.5303486330574366e-05,
      "loss": 3.5939,
      "step": 750
    },
    {
      "epoch": 0.28592927012791575,
      "grad_norm": 0.7638929486274719,
      "learning_rate": 4.5240782543265614e-05,
      "loss": 3.5775,
      "step": 760
    },
    {
      "epoch": 0.28969149736644095,
      "grad_norm": 0.780738115310669,
      "learning_rate": 4.517807875595686e-05,
      "loss": 3.5652,
      "step": 770
    },
    {
      "epoch": 0.29345372460496616,
      "grad_norm": 0.8021991848945618,
      "learning_rate": 4.511537496864811e-05,
      "loss": 3.5066,
      "step": 780
    },
    {
      "epoch": 0.29721595184349137,
      "grad_norm": 0.951396107673645,
      "learning_rate": 4.5052671181339356e-05,
      "loss": 3.6094,
      "step": 790
    },
    {
      "epoch": 0.3009781790820166,
      "grad_norm": 0.7705856561660767,
      "learning_rate": 4.4989967394030604e-05,
      "loss": 3.6104,
      "step": 800
    },
    {
      "epoch": 0.3047404063205418,
      "grad_norm": 0.8155247569084167,
      "learning_rate": 4.4927263606721844e-05,
      "loss": 3.5044,
      "step": 810
    },
    {
      "epoch": 0.308502633559067,
      "grad_norm": 0.8811495900154114,
      "learning_rate": 4.486455981941309e-05,
      "loss": 3.5017,
      "step": 820
    },
    {
      "epoch": 0.3122648607975922,
      "grad_norm": 0.8313271403312683,
      "learning_rate": 4.480185603210434e-05,
      "loss": 3.5486,
      "step": 830
    },
    {
      "epoch": 0.3160270880361174,
      "grad_norm": 0.7235888838768005,
      "learning_rate": 4.473915224479559e-05,
      "loss": 3.6178,
      "step": 840
    },
    {
      "epoch": 0.3197893152746426,
      "grad_norm": 0.7351295351982117,
      "learning_rate": 4.4676448457486834e-05,
      "loss": 3.4659,
      "step": 850
    },
    {
      "epoch": 0.3235515425131678,
      "grad_norm": 0.8546568751335144,
      "learning_rate": 4.461374467017808e-05,
      "loss": 3.5045,
      "step": 860
    },
    {
      "epoch": 0.327313769751693,
      "grad_norm": 0.8636930584907532,
      "learning_rate": 4.455104088286933e-05,
      "loss": 3.5547,
      "step": 870
    },
    {
      "epoch": 0.3310759969902182,
      "grad_norm": 0.7892867922782898,
      "learning_rate": 4.448833709556057e-05,
      "loss": 3.6564,
      "step": 880
    },
    {
      "epoch": 0.33483822422874343,
      "grad_norm": 0.9343810677528381,
      "learning_rate": 4.442563330825182e-05,
      "loss": 3.5926,
      "step": 890
    },
    {
      "epoch": 0.33860045146726864,
      "grad_norm": 0.8073914051055908,
      "learning_rate": 4.436292952094307e-05,
      "loss": 3.5165,
      "step": 900
    },
    {
      "epoch": 0.34236267870579384,
      "grad_norm": 1.0936226844787598,
      "learning_rate": 4.430022573363431e-05,
      "loss": 3.567,
      "step": 910
    },
    {
      "epoch": 0.34612490594431905,
      "grad_norm": 0.7938175201416016,
      "learning_rate": 4.423752194632556e-05,
      "loss": 3.5689,
      "step": 920
    },
    {
      "epoch": 0.34988713318284426,
      "grad_norm": 0.7873805165290833,
      "learning_rate": 4.417481815901681e-05,
      "loss": 3.5516,
      "step": 930
    },
    {
      "epoch": 0.35364936042136946,
      "grad_norm": 0.8970410823822021,
      "learning_rate": 4.4112114371708055e-05,
      "loss": 3.5243,
      "step": 940
    },
    {
      "epoch": 0.35741158765989467,
      "grad_norm": 1.1812431812286377,
      "learning_rate": 4.4049410584399295e-05,
      "loss": 3.5363,
      "step": 950
    },
    {
      "epoch": 0.3611738148984199,
      "grad_norm": 1.1200356483459473,
      "learning_rate": 4.398670679709055e-05,
      "loss": 3.6304,
      "step": 960
    },
    {
      "epoch": 0.3649360421369451,
      "grad_norm": 0.8608144521713257,
      "learning_rate": 4.39240030097818e-05,
      "loss": 3.4733,
      "step": 970
    },
    {
      "epoch": 0.3686982693754703,
      "grad_norm": 0.9298641681671143,
      "learning_rate": 4.386129922247304e-05,
      "loss": 3.5245,
      "step": 980
    },
    {
      "epoch": 0.3724604966139955,
      "grad_norm": 0.8584232330322266,
      "learning_rate": 4.3798595435164285e-05,
      "loss": 3.5575,
      "step": 990
    },
    {
      "epoch": 0.3762227238525207,
      "grad_norm": 0.8772707581520081,
      "learning_rate": 4.373589164785553e-05,
      "loss": 3.5172,
      "step": 1000
    },
    {
      "epoch": 0.3799849510910459,
      "grad_norm": 1.0566763877868652,
      "learning_rate": 4.367318786054678e-05,
      "loss": 3.624,
      "step": 1010
    },
    {
      "epoch": 0.3837471783295711,
      "grad_norm": 0.8823912739753723,
      "learning_rate": 4.361048407323803e-05,
      "loss": 3.524,
      "step": 1020
    },
    {
      "epoch": 0.3875094055680963,
      "grad_norm": 0.7390741109848022,
      "learning_rate": 4.3547780285929275e-05,
      "loss": 3.556,
      "step": 1030
    },
    {
      "epoch": 0.3912716328066215,
      "grad_norm": 0.7664147019386292,
      "learning_rate": 4.348507649862052e-05,
      "loss": 3.5134,
      "step": 1040
    },
    {
      "epoch": 0.39503386004514673,
      "grad_norm": 0.9068099856376648,
      "learning_rate": 4.342237271131176e-05,
      "loss": 3.5195,
      "step": 1050
    },
    {
      "epoch": 0.39879608728367194,
      "grad_norm": 0.8359951376914978,
      "learning_rate": 4.335966892400301e-05,
      "loss": 3.5426,
      "step": 1060
    },
    {
      "epoch": 0.40255831452219715,
      "grad_norm": 0.8283549547195435,
      "learning_rate": 4.329696513669426e-05,
      "loss": 3.5919,
      "step": 1070
    },
    {
      "epoch": 0.40632054176072235,
      "grad_norm": 1.0096465349197388,
      "learning_rate": 4.3234261349385506e-05,
      "loss": 3.5717,
      "step": 1080
    },
    {
      "epoch": 0.41008276899924756,
      "grad_norm": 1.2934074401855469,
      "learning_rate": 4.317155756207675e-05,
      "loss": 3.5377,
      "step": 1090
    },
    {
      "epoch": 0.41384499623777277,
      "grad_norm": 0.8948163986206055,
      "learning_rate": 4.3108853774768e-05,
      "loss": 3.4883,
      "step": 1100
    },
    {
      "epoch": 0.417607223476298,
      "grad_norm": 0.8734520673751831,
      "learning_rate": 4.304614998745924e-05,
      "loss": 3.5692,
      "step": 1110
    },
    {
      "epoch": 0.4213694507148232,
      "grad_norm": 0.76093989610672,
      "learning_rate": 4.298344620015049e-05,
      "loss": 3.5185,
      "step": 1120
    },
    {
      "epoch": 0.4251316779533484,
      "grad_norm": 0.9381303191184998,
      "learning_rate": 4.2920742412841736e-05,
      "loss": 3.6414,
      "step": 1130
    },
    {
      "epoch": 0.4288939051918736,
      "grad_norm": 1.105766773223877,
      "learning_rate": 4.2858038625532984e-05,
      "loss": 3.5922,
      "step": 1140
    },
    {
      "epoch": 0.4326561324303988,
      "grad_norm": 0.9164372682571411,
      "learning_rate": 4.279533483822423e-05,
      "loss": 3.5226,
      "step": 1150
    },
    {
      "epoch": 0.436418359668924,
      "grad_norm": 1.1614969968795776,
      "learning_rate": 4.273263105091548e-05,
      "loss": 3.5682,
      "step": 1160
    },
    {
      "epoch": 0.4401805869074492,
      "grad_norm": 0.813743531703949,
      "learning_rate": 4.2669927263606726e-05,
      "loss": 3.5058,
      "step": 1170
    },
    {
      "epoch": 0.4439428141459744,
      "grad_norm": 0.8475830554962158,
      "learning_rate": 4.260722347629797e-05,
      "loss": 3.4277,
      "step": 1180
    },
    {
      "epoch": 0.4477050413844996,
      "grad_norm": 0.8713101148605347,
      "learning_rate": 4.2544519688989214e-05,
      "loss": 3.6194,
      "step": 1190
    },
    {
      "epoch": 0.45146726862302483,
      "grad_norm": 0.8784815669059753,
      "learning_rate": 4.248181590168047e-05,
      "loss": 3.5518,
      "step": 1200
    },
    {
      "epoch": 0.45522949586155004,
      "grad_norm": 0.9212952852249146,
      "learning_rate": 4.241911211437171e-05,
      "loss": 3.4902,
      "step": 1210
    },
    {
      "epoch": 0.45899172310007524,
      "grad_norm": 0.9872576594352722,
      "learning_rate": 4.235640832706296e-05,
      "loss": 3.6398,
      "step": 1220
    },
    {
      "epoch": 0.46275395033860045,
      "grad_norm": 0.9532553553581238,
      "learning_rate": 4.2293704539754204e-05,
      "loss": 3.5214,
      "step": 1230
    },
    {
      "epoch": 0.46651617757712566,
      "grad_norm": 0.762376606464386,
      "learning_rate": 4.223100075244545e-05,
      "loss": 3.5441,
      "step": 1240
    },
    {
      "epoch": 0.47027840481565086,
      "grad_norm": 0.7885855436325073,
      "learning_rate": 4.216829696513669e-05,
      "loss": 3.5449,
      "step": 1250
    },
    {
      "epoch": 0.47404063205417607,
      "grad_norm": 0.9082849025726318,
      "learning_rate": 4.2105593177827947e-05,
      "loss": 3.4878,
      "step": 1260
    },
    {
      "epoch": 0.4778028592927013,
      "grad_norm": 0.9792376160621643,
      "learning_rate": 4.2042889390519194e-05,
      "loss": 3.5521,
      "step": 1270
    },
    {
      "epoch": 0.4815650865312265,
      "grad_norm": 0.9331873059272766,
      "learning_rate": 4.1980185603210435e-05,
      "loss": 3.497,
      "step": 1280
    },
    {
      "epoch": 0.4853273137697517,
      "grad_norm": 1.2257318496704102,
      "learning_rate": 4.191748181590168e-05,
      "loss": 3.5199,
      "step": 1290
    },
    {
      "epoch": 0.4890895410082769,
      "grad_norm": 0.9285126328468323,
      "learning_rate": 4.185477802859293e-05,
      "loss": 3.5875,
      "step": 1300
    },
    {
      "epoch": 0.4928517682468021,
      "grad_norm": 0.9907118082046509,
      "learning_rate": 4.179207424128417e-05,
      "loss": 3.4962,
      "step": 1310
    },
    {
      "epoch": 0.4966139954853273,
      "grad_norm": 2.0002856254577637,
      "learning_rate": 4.1729370453975425e-05,
      "loss": 3.4556,
      "step": 1320
    },
    {
      "epoch": 0.5003762227238525,
      "grad_norm": 1.4549533128738403,
      "learning_rate": 4.166666666666667e-05,
      "loss": 3.5164,
      "step": 1330
    },
    {
      "epoch": 0.5041384499623778,
      "grad_norm": 0.9615985751152039,
      "learning_rate": 4.160396287935792e-05,
      "loss": 3.5932,
      "step": 1340
    },
    {
      "epoch": 0.5079006772009029,
      "grad_norm": 1.1852055788040161,
      "learning_rate": 4.154125909204916e-05,
      "loss": 3.5966,
      "step": 1350
    },
    {
      "epoch": 0.5116629044394282,
      "grad_norm": 1.0369983911514282,
      "learning_rate": 4.147855530474041e-05,
      "loss": 3.5811,
      "step": 1360
    },
    {
      "epoch": 0.5154251316779533,
      "grad_norm": 0.8476911187171936,
      "learning_rate": 4.1415851517431655e-05,
      "loss": 3.5775,
      "step": 1370
    },
    {
      "epoch": 0.5191873589164786,
      "grad_norm": 1.2221064567565918,
      "learning_rate": 4.1353147730122896e-05,
      "loss": 3.4846,
      "step": 1380
    },
    {
      "epoch": 0.5229495861550038,
      "grad_norm": 1.2114607095718384,
      "learning_rate": 4.129044394281415e-05,
      "loss": 3.5253,
      "step": 1390
    },
    {
      "epoch": 0.526711813393529,
      "grad_norm": 0.847859263420105,
      "learning_rate": 4.12277401555054e-05,
      "loss": 3.5484,
      "step": 1400
    },
    {
      "epoch": 0.5304740406320542,
      "grad_norm": 1.065980315208435,
      "learning_rate": 4.116503636819664e-05,
      "loss": 3.5502,
      "step": 1410
    },
    {
      "epoch": 0.5342362678705794,
      "grad_norm": 0.9408032298088074,
      "learning_rate": 4.1102332580887886e-05,
      "loss": 3.5102,
      "step": 1420
    },
    {
      "epoch": 0.5379984951091046,
      "grad_norm": 0.8753692507743835,
      "learning_rate": 4.103962879357913e-05,
      "loss": 3.4858,
      "step": 1430
    },
    {
      "epoch": 0.5417607223476298,
      "grad_norm": 0.876110315322876,
      "learning_rate": 4.097692500627038e-05,
      "loss": 3.546,
      "step": 1440
    },
    {
      "epoch": 0.545522949586155,
      "grad_norm": 0.9895002245903015,
      "learning_rate": 4.091422121896163e-05,
      "loss": 3.6079,
      "step": 1450
    },
    {
      "epoch": 0.5492851768246803,
      "grad_norm": 1.5227854251861572,
      "learning_rate": 4.0851517431652876e-05,
      "loss": 3.6427,
      "step": 1460
    },
    {
      "epoch": 0.5530474040632054,
      "grad_norm": 1.595651388168335,
      "learning_rate": 4.078881364434412e-05,
      "loss": 3.5769,
      "step": 1470
    },
    {
      "epoch": 0.5568096313017307,
      "grad_norm": 1.0548607110977173,
      "learning_rate": 4.0726109857035364e-05,
      "loss": 3.5253,
      "step": 1480
    },
    {
      "epoch": 0.5605718585402558,
      "grad_norm": 0.9028698205947876,
      "learning_rate": 4.066340606972661e-05,
      "loss": 3.4992,
      "step": 1490
    },
    {
      "epoch": 0.5643340857787811,
      "grad_norm": 0.890832245349884,
      "learning_rate": 4.060070228241786e-05,
      "loss": 3.4218,
      "step": 1500
    },
    {
      "epoch": 0.5680963130173062,
      "grad_norm": 0.8465591669082642,
      "learning_rate": 4.0537998495109106e-05,
      "loss": 3.5179,
      "step": 1510
    },
    {
      "epoch": 0.5718585402558315,
      "grad_norm": 0.9319629669189453,
      "learning_rate": 4.0475294707800354e-05,
      "loss": 3.4974,
      "step": 1520
    },
    {
      "epoch": 0.5756207674943566,
      "grad_norm": 1.1628036499023438,
      "learning_rate": 4.04125909204916e-05,
      "loss": 3.5005,
      "step": 1530
    },
    {
      "epoch": 0.5793829947328819,
      "grad_norm": 0.9147087931632996,
      "learning_rate": 4.034988713318285e-05,
      "loss": 3.4776,
      "step": 1540
    },
    {
      "epoch": 0.5831452219714071,
      "grad_norm": 0.9324248433113098,
      "learning_rate": 4.028718334587409e-05,
      "loss": 3.5758,
      "step": 1550
    },
    {
      "epoch": 0.5869074492099323,
      "grad_norm": 1.2086009979248047,
      "learning_rate": 4.022447955856534e-05,
      "loss": 3.5124,
      "step": 1560
    },
    {
      "epoch": 0.5906696764484575,
      "grad_norm": 0.9893823266029358,
      "learning_rate": 4.016177577125659e-05,
      "loss": 3.4836,
      "step": 1570
    },
    {
      "epoch": 0.5944319036869827,
      "grad_norm": 1.1001805067062378,
      "learning_rate": 4.009907198394783e-05,
      "loss": 3.6416,
      "step": 1580
    },
    {
      "epoch": 0.5981941309255079,
      "grad_norm": 0.7833687663078308,
      "learning_rate": 4.003636819663908e-05,
      "loss": 3.5324,
      "step": 1590
    },
    {
      "epoch": 0.6019563581640331,
      "grad_norm": 0.9166271686553955,
      "learning_rate": 3.9973664409330327e-05,
      "loss": 3.529,
      "step": 1600
    },
    {
      "epoch": 0.6057185854025583,
      "grad_norm": 0.9420860409736633,
      "learning_rate": 3.991096062202157e-05,
      "loss": 3.4633,
      "step": 1610
    },
    {
      "epoch": 0.6094808126410836,
      "grad_norm": 0.9171743392944336,
      "learning_rate": 3.9848256834712815e-05,
      "loss": 3.553,
      "step": 1620
    },
    {
      "epoch": 0.6132430398796087,
      "grad_norm": 1.1161267757415771,
      "learning_rate": 3.978555304740407e-05,
      "loss": 3.5445,
      "step": 1630
    },
    {
      "epoch": 0.617005267118134,
      "grad_norm": 1.082915186882019,
      "learning_rate": 3.972284926009531e-05,
      "loss": 3.5539,
      "step": 1640
    },
    {
      "epoch": 0.6207674943566591,
      "grad_norm": 1.005781650543213,
      "learning_rate": 3.966014547278656e-05,
      "loss": 3.5303,
      "step": 1650
    },
    {
      "epoch": 0.6245297215951844,
      "grad_norm": 1.1032356023788452,
      "learning_rate": 3.9597441685477805e-05,
      "loss": 3.5259,
      "step": 1660
    },
    {
      "epoch": 0.6282919488337095,
      "grad_norm": 1.0263086557388306,
      "learning_rate": 3.953473789816905e-05,
      "loss": 3.4949,
      "step": 1670
    },
    {
      "epoch": 0.6320541760722348,
      "grad_norm": 0.9202127456665039,
      "learning_rate": 3.947203411086029e-05,
      "loss": 3.5804,
      "step": 1680
    },
    {
      "epoch": 0.63581640331076,
      "grad_norm": 0.9784097075462341,
      "learning_rate": 3.940933032355155e-05,
      "loss": 3.5198,
      "step": 1690
    },
    {
      "epoch": 0.6395786305492852,
      "grad_norm": 1.0296858549118042,
      "learning_rate": 3.9346626536242794e-05,
      "loss": 3.6005,
      "step": 1700
    },
    {
      "epoch": 0.6433408577878104,
      "grad_norm": 1.1091480255126953,
      "learning_rate": 3.9283922748934035e-05,
      "loss": 3.4896,
      "step": 1710
    },
    {
      "epoch": 0.6471030850263356,
      "grad_norm": 1.2162041664123535,
      "learning_rate": 3.922121896162528e-05,
      "loss": 3.486,
      "step": 1720
    },
    {
      "epoch": 0.6508653122648608,
      "grad_norm": 1.2040187120437622,
      "learning_rate": 3.915851517431653e-05,
      "loss": 3.5373,
      "step": 1730
    },
    {
      "epoch": 0.654627539503386,
      "grad_norm": 0.882817804813385,
      "learning_rate": 3.909581138700778e-05,
      "loss": 3.5688,
      "step": 1740
    },
    {
      "epoch": 0.6583897667419112,
      "grad_norm": 1.1199625730514526,
      "learning_rate": 3.9033107599699025e-05,
      "loss": 3.6284,
      "step": 1750
    },
    {
      "epoch": 0.6621519939804364,
      "grad_norm": 1.546141266822815,
      "learning_rate": 3.897040381239027e-05,
      "loss": 3.5078,
      "step": 1760
    },
    {
      "epoch": 0.6659142212189616,
      "grad_norm": 1.1259433031082153,
      "learning_rate": 3.890770002508152e-05,
      "loss": 3.5646,
      "step": 1770
    },
    {
      "epoch": 0.6696764484574869,
      "grad_norm": 1.021450161933899,
      "learning_rate": 3.884499623777276e-05,
      "loss": 3.45,
      "step": 1780
    },
    {
      "epoch": 0.673438675696012,
      "grad_norm": 1.0079498291015625,
      "learning_rate": 3.878229245046401e-05,
      "loss": 3.5139,
      "step": 1790
    },
    {
      "epoch": 0.6772009029345373,
      "grad_norm": 1.0461796522140503,
      "learning_rate": 3.8719588663155256e-05,
      "loss": 3.5193,
      "step": 1800
    },
    {
      "epoch": 0.6809631301730624,
      "grad_norm": 1.2123372554779053,
      "learning_rate": 3.86568848758465e-05,
      "loss": 3.4816,
      "step": 1810
    },
    {
      "epoch": 0.6847253574115877,
      "grad_norm": 0.9695298075675964,
      "learning_rate": 3.859418108853775e-05,
      "loss": 3.4314,
      "step": 1820
    },
    {
      "epoch": 0.6884875846501128,
      "grad_norm": 0.9598941802978516,
      "learning_rate": 3.8531477301229e-05,
      "loss": 3.6312,
      "step": 1830
    },
    {
      "epoch": 0.6922498118886381,
      "grad_norm": 1.1239124536514282,
      "learning_rate": 3.8468773513920245e-05,
      "loss": 3.5059,
      "step": 1840
    },
    {
      "epoch": 0.6960120391271633,
      "grad_norm": 0.972319483757019,
      "learning_rate": 3.8406069726611486e-05,
      "loss": 3.4935,
      "step": 1850
    },
    {
      "epoch": 0.6997742663656885,
      "grad_norm": 0.8668533563613892,
      "learning_rate": 3.8343365939302734e-05,
      "loss": 3.5291,
      "step": 1860
    },
    {
      "epoch": 0.7035364936042137,
      "grad_norm": 0.9287490844726562,
      "learning_rate": 3.828066215199399e-05,
      "loss": 3.5683,
      "step": 1870
    },
    {
      "epoch": 0.7072987208427389,
      "grad_norm": 0.8761811852455139,
      "learning_rate": 3.821795836468523e-05,
      "loss": 3.5165,
      "step": 1880
    },
    {
      "epoch": 0.7110609480812641,
      "grad_norm": 1.5588765144348145,
      "learning_rate": 3.8155254577376476e-05,
      "loss": 3.4259,
      "step": 1890
    },
    {
      "epoch": 0.7148231753197893,
      "grad_norm": 1.2305078506469727,
      "learning_rate": 3.8092550790067723e-05,
      "loss": 3.4333,
      "step": 1900
    },
    {
      "epoch": 0.7185854025583145,
      "grad_norm": 1.154330849647522,
      "learning_rate": 3.8029847002758964e-05,
      "loss": 3.5294,
      "step": 1910
    },
    {
      "epoch": 0.7223476297968398,
      "grad_norm": 1.1230725049972534,
      "learning_rate": 3.796714321545021e-05,
      "loss": 3.4408,
      "step": 1920
    },
    {
      "epoch": 0.7261098570353649,
      "grad_norm": 1.0108915567398071,
      "learning_rate": 3.7904439428141466e-05,
      "loss": 3.3902,
      "step": 1930
    },
    {
      "epoch": 0.7298720842738902,
      "grad_norm": 0.8698908090591431,
      "learning_rate": 3.7841735640832706e-05,
      "loss": 3.5406,
      "step": 1940
    },
    {
      "epoch": 0.7336343115124153,
      "grad_norm": 1.0843769311904907,
      "learning_rate": 3.7779031853523954e-05,
      "loss": 3.5355,
      "step": 1950
    },
    {
      "epoch": 0.7373965387509406,
      "grad_norm": 1.0933791399002075,
      "learning_rate": 3.77163280662152e-05,
      "loss": 3.4453,
      "step": 1960
    },
    {
      "epoch": 0.7411587659894657,
      "grad_norm": 0.9254280924797058,
      "learning_rate": 3.765362427890645e-05,
      "loss": 3.5406,
      "step": 1970
    },
    {
      "epoch": 0.744920993227991,
      "grad_norm": 0.9821330904960632,
      "learning_rate": 3.759092049159769e-05,
      "loss": 3.4704,
      "step": 1980
    },
    {
      "epoch": 0.7486832204665161,
      "grad_norm": 0.9317517876625061,
      "learning_rate": 3.7528216704288944e-05,
      "loss": 3.5115,
      "step": 1990
    },
    {
      "epoch": 0.7524454477050414,
      "grad_norm": 0.9792134165763855,
      "learning_rate": 3.746551291698019e-05,
      "loss": 3.5451,
      "step": 2000
    },
    {
      "epoch": 0.7562076749435666,
      "grad_norm": 0.8656167387962341,
      "learning_rate": 3.740280912967143e-05,
      "loss": 3.5564,
      "step": 2010
    },
    {
      "epoch": 0.7599699021820918,
      "grad_norm": 1.022873878479004,
      "learning_rate": 3.734010534236268e-05,
      "loss": 3.4772,
      "step": 2020
    },
    {
      "epoch": 0.763732129420617,
      "grad_norm": 0.8996416330337524,
      "learning_rate": 3.727740155505393e-05,
      "loss": 3.4397,
      "step": 2030
    },
    {
      "epoch": 0.7674943566591422,
      "grad_norm": 0.9000985622406006,
      "learning_rate": 3.7214697767745174e-05,
      "loss": 3.5423,
      "step": 2040
    },
    {
      "epoch": 0.7712565838976674,
      "grad_norm": 0.9074175953865051,
      "learning_rate": 3.715199398043642e-05,
      "loss": 3.6346,
      "step": 2050
    },
    {
      "epoch": 0.7750188111361926,
      "grad_norm": 1.1168574094772339,
      "learning_rate": 3.708929019312767e-05,
      "loss": 3.4928,
      "step": 2060
    },
    {
      "epoch": 0.7787810383747178,
      "grad_norm": 0.9461795687675476,
      "learning_rate": 3.702658640581892e-05,
      "loss": 3.5331,
      "step": 2070
    },
    {
      "epoch": 0.782543265613243,
      "grad_norm": 1.1838970184326172,
      "learning_rate": 3.696388261851016e-05,
      "loss": 3.5419,
      "step": 2080
    },
    {
      "epoch": 0.7863054928517682,
      "grad_norm": 1.1895771026611328,
      "learning_rate": 3.6901178831201405e-05,
      "loss": 3.5505,
      "step": 2090
    },
    {
      "epoch": 0.7900677200902935,
      "grad_norm": 1.0143934488296509,
      "learning_rate": 3.683847504389265e-05,
      "loss": 3.606,
      "step": 2100
    },
    {
      "epoch": 0.7938299473288186,
      "grad_norm": 0.949081540107727,
      "learning_rate": 3.67757712565839e-05,
      "loss": 3.512,
      "step": 2110
    },
    {
      "epoch": 0.7975921745673439,
      "grad_norm": 1.0507535934448242,
      "learning_rate": 3.671306746927515e-05,
      "loss": 3.4932,
      "step": 2120
    },
    {
      "epoch": 0.801354401805869,
      "grad_norm": 0.8821513056755066,
      "learning_rate": 3.6650363681966395e-05,
      "loss": 3.4087,
      "step": 2130
    },
    {
      "epoch": 0.8051166290443943,
      "grad_norm": 0.9623011946678162,
      "learning_rate": 3.6587659894657635e-05,
      "loss": 3.6326,
      "step": 2140
    },
    {
      "epoch": 0.8088788562829194,
      "grad_norm": 0.9832396507263184,
      "learning_rate": 3.652495610734888e-05,
      "loss": 3.5037,
      "step": 2150
    },
    {
      "epoch": 0.8126410835214447,
      "grad_norm": 0.9989194869995117,
      "learning_rate": 3.646225232004013e-05,
      "loss": 3.5108,
      "step": 2160
    },
    {
      "epoch": 0.8164033107599699,
      "grad_norm": 1.3392068147659302,
      "learning_rate": 3.639954853273138e-05,
      "loss": 3.4911,
      "step": 2170
    },
    {
      "epoch": 0.8201655379984951,
      "grad_norm": 1.0381497144699097,
      "learning_rate": 3.6336844745422625e-05,
      "loss": 3.5594,
      "step": 2180
    },
    {
      "epoch": 0.8239277652370203,
      "grad_norm": 1.0547653436660767,
      "learning_rate": 3.627414095811387e-05,
      "loss": 3.5059,
      "step": 2190
    },
    {
      "epoch": 0.8276899924755455,
      "grad_norm": 0.9895632863044739,
      "learning_rate": 3.621143717080512e-05,
      "loss": 3.5958,
      "step": 2200
    },
    {
      "epoch": 0.8314522197140707,
      "grad_norm": 1.1218429803848267,
      "learning_rate": 3.614873338349636e-05,
      "loss": 3.5462,
      "step": 2210
    },
    {
      "epoch": 0.835214446952596,
      "grad_norm": 0.9713543057441711,
      "learning_rate": 3.608602959618761e-05,
      "loss": 3.58,
      "step": 2220
    },
    {
      "epoch": 0.8389766741911211,
      "grad_norm": 1.1047937870025635,
      "learning_rate": 3.602332580887886e-05,
      "loss": 3.5342,
      "step": 2230
    },
    {
      "epoch": 0.8427389014296464,
      "grad_norm": 0.9951563477516174,
      "learning_rate": 3.59606220215701e-05,
      "loss": 3.4566,
      "step": 2240
    },
    {
      "epoch": 0.8465011286681715,
      "grad_norm": 1.038949728012085,
      "learning_rate": 3.589791823426135e-05,
      "loss": 3.4789,
      "step": 2250
    },
    {
      "epoch": 0.8502633559066968,
      "grad_norm": 0.9575079679489136,
      "learning_rate": 3.58352144469526e-05,
      "loss": 3.5835,
      "step": 2260
    },
    {
      "epoch": 0.8540255831452219,
      "grad_norm": 0.9235500693321228,
      "learning_rate": 3.5772510659643846e-05,
      "loss": 3.5403,
      "step": 2270
    },
    {
      "epoch": 0.8577878103837472,
      "grad_norm": 0.980503261089325,
      "learning_rate": 3.5709806872335086e-05,
      "loss": 3.5564,
      "step": 2280
    },
    {
      "epoch": 0.8615500376222723,
      "grad_norm": 1.005663275718689,
      "learning_rate": 3.564710308502634e-05,
      "loss": 3.5133,
      "step": 2290
    },
    {
      "epoch": 0.8653122648607976,
      "grad_norm": 1.1457469463348389,
      "learning_rate": 3.558439929771759e-05,
      "loss": 3.5337,
      "step": 2300
    },
    {
      "epoch": 0.8690744920993227,
      "grad_norm": 0.9796962141990662,
      "learning_rate": 3.552169551040883e-05,
      "loss": 3.4778,
      "step": 2310
    },
    {
      "epoch": 0.872836719337848,
      "grad_norm": 1.1885502338409424,
      "learning_rate": 3.5458991723100076e-05,
      "loss": 3.5702,
      "step": 2320
    },
    {
      "epoch": 0.8765989465763732,
      "grad_norm": 0.9779431223869324,
      "learning_rate": 3.5396287935791324e-05,
      "loss": 3.5669,
      "step": 2330
    },
    {
      "epoch": 0.8803611738148984,
      "grad_norm": 1.201732873916626,
      "learning_rate": 3.533358414848257e-05,
      "loss": 3.4113,
      "step": 2340
    },
    {
      "epoch": 0.8841234010534236,
      "grad_norm": 0.9942662715911865,
      "learning_rate": 3.527088036117382e-05,
      "loss": 3.4946,
      "step": 2350
    },
    {
      "epoch": 0.8878856282919488,
      "grad_norm": 1.1089541912078857,
      "learning_rate": 3.5208176573865066e-05,
      "loss": 3.5173,
      "step": 2360
    },
    {
      "epoch": 0.891647855530474,
      "grad_norm": 1.2335504293441772,
      "learning_rate": 3.5145472786556314e-05,
      "loss": 3.4679,
      "step": 2370
    },
    {
      "epoch": 0.8954100827689992,
      "grad_norm": 1.2932016849517822,
      "learning_rate": 3.5082768999247554e-05,
      "loss": 3.4864,
      "step": 2380
    },
    {
      "epoch": 0.8991723100075244,
      "grad_norm": 1.021412968635559,
      "learning_rate": 3.50200652119388e-05,
      "loss": 3.5417,
      "step": 2390
    },
    {
      "epoch": 0.9029345372460497,
      "grad_norm": 1.0845016241073608,
      "learning_rate": 3.495736142463005e-05,
      "loss": 3.6005,
      "step": 2400
    },
    {
      "epoch": 0.9066967644845748,
      "grad_norm": 0.9690078496932983,
      "learning_rate": 3.48946576373213e-05,
      "loss": 3.4609,
      "step": 2410
    },
    {
      "epoch": 0.9104589917231001,
      "grad_norm": 0.97257000207901,
      "learning_rate": 3.4831953850012544e-05,
      "loss": 3.4821,
      "step": 2420
    },
    {
      "epoch": 0.9142212189616253,
      "grad_norm": 0.9591728448867798,
      "learning_rate": 3.476925006270379e-05,
      "loss": 3.4158,
      "step": 2430
    },
    {
      "epoch": 0.9179834462001505,
      "grad_norm": 1.0417454242706299,
      "learning_rate": 3.470654627539503e-05,
      "loss": 3.5437,
      "step": 2440
    },
    {
      "epoch": 0.9217456734386757,
      "grad_norm": 1.0874089002609253,
      "learning_rate": 3.464384248808628e-05,
      "loss": 3.4954,
      "step": 2450
    },
    {
      "epoch": 0.9255079006772009,
      "grad_norm": 0.9849978685379028,
      "learning_rate": 3.458113870077753e-05,
      "loss": 3.563,
      "step": 2460
    },
    {
      "epoch": 0.9292701279157262,
      "grad_norm": 0.9653158783912659,
      "learning_rate": 3.4518434913468775e-05,
      "loss": 3.43,
      "step": 2470
    },
    {
      "epoch": 0.9330323551542513,
      "grad_norm": 0.9454616904258728,
      "learning_rate": 3.445573112616002e-05,
      "loss": 3.5713,
      "step": 2480
    },
    {
      "epoch": 0.9367945823927766,
      "grad_norm": 1.0860652923583984,
      "learning_rate": 3.439302733885127e-05,
      "loss": 3.5524,
      "step": 2490
    },
    {
      "epoch": 0.9405568096313017,
      "grad_norm": 1.0961986780166626,
      "learning_rate": 3.433032355154252e-05,
      "loss": 3.4908,
      "step": 2500
    },
    {
      "epoch": 0.944319036869827,
      "grad_norm": 0.9445948004722595,
      "learning_rate": 3.426761976423376e-05,
      "loss": 3.4631,
      "step": 2510
    },
    {
      "epoch": 0.9480812641083521,
      "grad_norm": 1.0058468580245972,
      "learning_rate": 3.4204915976925005e-05,
      "loss": 3.515,
      "step": 2520
    },
    {
      "epoch": 0.9518434913468774,
      "grad_norm": 1.5214319229125977,
      "learning_rate": 3.414221218961626e-05,
      "loss": 3.5321,
      "step": 2530
    },
    {
      "epoch": 0.9556057185854026,
      "grad_norm": 1.1884806156158447,
      "learning_rate": 3.40795084023075e-05,
      "loss": 3.5215,
      "step": 2540
    },
    {
      "epoch": 0.9593679458239278,
      "grad_norm": 0.9874122738838196,
      "learning_rate": 3.401680461499875e-05,
      "loss": 3.5204,
      "step": 2550
    },
    {
      "epoch": 0.963130173062453,
      "grad_norm": 1.1420950889587402,
      "learning_rate": 3.3954100827689995e-05,
      "loss": 3.5547,
      "step": 2560
    },
    {
      "epoch": 0.9668924003009782,
      "grad_norm": 0.9761039614677429,
      "learning_rate": 3.389139704038124e-05,
      "loss": 3.5574,
      "step": 2570
    },
    {
      "epoch": 0.9706546275395034,
      "grad_norm": 1.0361682176589966,
      "learning_rate": 3.382869325307248e-05,
      "loss": 3.4978,
      "step": 2580
    },
    {
      "epoch": 0.9744168547780286,
      "grad_norm": 1.1132639646530151,
      "learning_rate": 3.376598946576373e-05,
      "loss": 3.4692,
      "step": 2590
    },
    {
      "epoch": 0.9781790820165538,
      "grad_norm": 1.43947434425354,
      "learning_rate": 3.3703285678454985e-05,
      "loss": 3.5727,
      "step": 2600
    },
    {
      "epoch": 0.981941309255079,
      "grad_norm": 1.1721796989440918,
      "learning_rate": 3.3640581891146226e-05,
      "loss": 3.5924,
      "step": 2610
    },
    {
      "epoch": 0.9857035364936042,
      "grad_norm": 1.0303969383239746,
      "learning_rate": 3.357787810383747e-05,
      "loss": 3.5863,
      "step": 2620
    },
    {
      "epoch": 0.9894657637321295,
      "grad_norm": 1.0614999532699585,
      "learning_rate": 3.351517431652872e-05,
      "loss": 3.5039,
      "step": 2630
    },
    {
      "epoch": 0.9932279909706546,
      "grad_norm": 1.2279466390609741,
      "learning_rate": 3.345247052921996e-05,
      "loss": 3.4347,
      "step": 2640
    },
    {
      "epoch": 0.9969902182091799,
      "grad_norm": 1.1976501941680908,
      "learning_rate": 3.338976674191121e-05,
      "loss": 3.4542,
      "step": 2650
    },
    {
      "epoch": 1.000752445447705,
      "grad_norm": 1.1677407026290894,
      "learning_rate": 3.332706295460246e-05,
      "loss": 3.565,
      "step": 2660
    },
    {
      "epoch": 1.0045146726862302,
      "grad_norm": 1.2098830938339233,
      "learning_rate": 3.326435916729371e-05,
      "loss": 3.5148,
      "step": 2670
    },
    {
      "epoch": 1.0082768999247556,
      "grad_norm": 1.2253913879394531,
      "learning_rate": 3.320165537998495e-05,
      "loss": 3.5336,
      "step": 2680
    },
    {
      "epoch": 1.0120391271632807,
      "grad_norm": 1.2021231651306152,
      "learning_rate": 3.31389515926762e-05,
      "loss": 3.4704,
      "step": 2690
    },
    {
      "epoch": 1.0158013544018059,
      "grad_norm": 1.0175576210021973,
      "learning_rate": 3.3076247805367446e-05,
      "loss": 3.5587,
      "step": 2700
    },
    {
      "epoch": 1.019563581640331,
      "grad_norm": 1.1060560941696167,
      "learning_rate": 3.301354401805869e-05,
      "loss": 3.5166,
      "step": 2710
    },
    {
      "epoch": 1.0233258088788564,
      "grad_norm": 1.131692886352539,
      "learning_rate": 3.295084023074994e-05,
      "loss": 3.415,
      "step": 2720
    },
    {
      "epoch": 1.0270880361173815,
      "grad_norm": 0.9778133034706116,
      "learning_rate": 3.288813644344119e-05,
      "loss": 3.4877,
      "step": 2730
    },
    {
      "epoch": 1.0308502633559067,
      "grad_norm": 1.1420732736587524,
      "learning_rate": 3.282543265613243e-05,
      "loss": 3.4179,
      "step": 2740
    },
    {
      "epoch": 1.0346124905944318,
      "grad_norm": 1.2867977619171143,
      "learning_rate": 3.276272886882368e-05,
      "loss": 3.4711,
      "step": 2750
    },
    {
      "epoch": 1.0383747178329572,
      "grad_norm": 1.0978456735610962,
      "learning_rate": 3.2700025081514924e-05,
      "loss": 3.4585,
      "step": 2760
    },
    {
      "epoch": 1.0421369450714824,
      "grad_norm": 1.1384553909301758,
      "learning_rate": 3.263732129420617e-05,
      "loss": 3.433,
      "step": 2770
    },
    {
      "epoch": 1.0458991723100075,
      "grad_norm": 1.0165222883224487,
      "learning_rate": 3.257461750689742e-05,
      "loss": 3.453,
      "step": 2780
    },
    {
      "epoch": 1.0496613995485327,
      "grad_norm": 0.9924663305282593,
      "learning_rate": 3.2511913719588667e-05,
      "loss": 3.4963,
      "step": 2790
    },
    {
      "epoch": 1.053423626787058,
      "grad_norm": 1.2087186574935913,
      "learning_rate": 3.2449209932279914e-05,
      "loss": 3.5639,
      "step": 2800
    },
    {
      "epoch": 1.0571858540255832,
      "grad_norm": 1.1550973653793335,
      "learning_rate": 3.2386506144971155e-05,
      "loss": 3.5056,
      "step": 2810
    },
    {
      "epoch": 1.0609480812641083,
      "grad_norm": 1.1618335247039795,
      "learning_rate": 3.23238023576624e-05,
      "loss": 3.4891,
      "step": 2820
    },
    {
      "epoch": 1.0647103085026335,
      "grad_norm": 1.1432732343673706,
      "learning_rate": 3.226109857035365e-05,
      "loss": 3.4792,
      "step": 2830
    },
    {
      "epoch": 1.0684725357411589,
      "grad_norm": 1.0019789934158325,
      "learning_rate": 3.21983947830449e-05,
      "loss": 3.5121,
      "step": 2840
    },
    {
      "epoch": 1.072234762979684,
      "grad_norm": 2.0755910873413086,
      "learning_rate": 3.2135690995736145e-05,
      "loss": 3.4511,
      "step": 2850
    },
    {
      "epoch": 1.0759969902182092,
      "grad_norm": 1.2326507568359375,
      "learning_rate": 3.207298720842739e-05,
      "loss": 3.4899,
      "step": 2860
    },
    {
      "epoch": 1.0797592174567343,
      "grad_norm": 0.9945504665374756,
      "learning_rate": 3.201028342111864e-05,
      "loss": 3.5436,
      "step": 2870
    },
    {
      "epoch": 1.0835214446952597,
      "grad_norm": 1.3538087606430054,
      "learning_rate": 3.194757963380988e-05,
      "loss": 3.5548,
      "step": 2880
    },
    {
      "epoch": 1.0872836719337848,
      "grad_norm": 1.3678208589553833,
      "learning_rate": 3.188487584650113e-05,
      "loss": 3.5532,
      "step": 2890
    },
    {
      "epoch": 1.09104589917231,
      "grad_norm": 1.0610567331314087,
      "learning_rate": 3.182217205919238e-05,
      "loss": 3.5289,
      "step": 2900
    },
    {
      "epoch": 1.0948081264108351,
      "grad_norm": 1.2615958452224731,
      "learning_rate": 3.175946827188362e-05,
      "loss": 3.4854,
      "step": 2910
    },
    {
      "epoch": 1.0985703536493605,
      "grad_norm": 0.956061065196991,
      "learning_rate": 3.169676448457487e-05,
      "loss": 3.5253,
      "step": 2920
    },
    {
      "epoch": 1.1023325808878857,
      "grad_norm": 1.12215256690979,
      "learning_rate": 3.163406069726612e-05,
      "loss": 3.4753,
      "step": 2930
    },
    {
      "epoch": 1.1060948081264108,
      "grad_norm": 1.13214910030365,
      "learning_rate": 3.157135690995736e-05,
      "loss": 3.4979,
      "step": 2940
    },
    {
      "epoch": 1.109857035364936,
      "grad_norm": 1.2721657752990723,
      "learning_rate": 3.1508653122648606e-05,
      "loss": 3.4694,
      "step": 2950
    },
    {
      "epoch": 1.1136192626034613,
      "grad_norm": 1.1230547428131104,
      "learning_rate": 3.144594933533986e-05,
      "loss": 3.4075,
      "step": 2960
    },
    {
      "epoch": 1.1173814898419865,
      "grad_norm": 1.1492677927017212,
      "learning_rate": 3.13832455480311e-05,
      "loss": 3.5467,
      "step": 2970
    },
    {
      "epoch": 1.1211437170805116,
      "grad_norm": 1.1029022932052612,
      "learning_rate": 3.132054176072235e-05,
      "loss": 3.5713,
      "step": 2980
    },
    {
      "epoch": 1.1249059443190368,
      "grad_norm": 0.9533097743988037,
      "learning_rate": 3.1257837973413596e-05,
      "loss": 3.5218,
      "step": 2990
    },
    {
      "epoch": 1.1286681715575622,
      "grad_norm": 1.0271074771881104,
      "learning_rate": 3.119513418610484e-05,
      "loss": 3.5877,
      "step": 3000
    },
    {
      "epoch": 1.1324303987960873,
      "grad_norm": 0.9409724473953247,
      "learning_rate": 3.1132430398796084e-05,
      "loss": 3.478,
      "step": 3010
    },
    {
      "epoch": 1.1361926260346125,
      "grad_norm": 1.1032071113586426,
      "learning_rate": 3.106972661148734e-05,
      "loss": 3.4617,
      "step": 3020
    },
    {
      "epoch": 1.1399548532731376,
      "grad_norm": 1.3232048749923706,
      "learning_rate": 3.1007022824178585e-05,
      "loss": 3.5095,
      "step": 3030
    },
    {
      "epoch": 1.143717080511663,
      "grad_norm": 0.970065176486969,
      "learning_rate": 3.0944319036869826e-05,
      "loss": 3.5219,
      "step": 3040
    },
    {
      "epoch": 1.1474793077501881,
      "grad_norm": 1.0509859323501587,
      "learning_rate": 3.0881615249561074e-05,
      "loss": 3.5465,
      "step": 3050
    },
    {
      "epoch": 1.1512415349887133,
      "grad_norm": 0.9419724941253662,
      "learning_rate": 3.081891146225232e-05,
      "loss": 3.4703,
      "step": 3060
    },
    {
      "epoch": 1.1550037622272384,
      "grad_norm": 1.138426423072815,
      "learning_rate": 3.075620767494357e-05,
      "loss": 3.492,
      "step": 3070
    },
    {
      "epoch": 1.1587659894657638,
      "grad_norm": 1.143176555633545,
      "learning_rate": 3.0693503887634816e-05,
      "loss": 3.5321,
      "step": 3080
    },
    {
      "epoch": 1.162528216704289,
      "grad_norm": 1.0378057956695557,
      "learning_rate": 3.0630800100326063e-05,
      "loss": 3.4015,
      "step": 3090
    },
    {
      "epoch": 1.1662904439428141,
      "grad_norm": 1.3076080083847046,
      "learning_rate": 3.056809631301731e-05,
      "loss": 3.5753,
      "step": 3100
    },
    {
      "epoch": 1.1700526711813393,
      "grad_norm": 1.349342942237854,
      "learning_rate": 3.0505392525708555e-05,
      "loss": 3.4182,
      "step": 3110
    },
    {
      "epoch": 1.1738148984198646,
      "grad_norm": 1.1668602228164673,
      "learning_rate": 3.04426887383998e-05,
      "loss": 3.5416,
      "step": 3120
    },
    {
      "epoch": 1.1775771256583898,
      "grad_norm": 1.392462134361267,
      "learning_rate": 3.0379984951091047e-05,
      "loss": 3.4554,
      "step": 3130
    },
    {
      "epoch": 1.181339352896915,
      "grad_norm": 1.2505967617034912,
      "learning_rate": 3.0317281163782297e-05,
      "loss": 3.4985,
      "step": 3140
    },
    {
      "epoch": 1.18510158013544,
      "grad_norm": 1.3440443277359009,
      "learning_rate": 3.025457737647354e-05,
      "loss": 3.5509,
      "step": 3150
    },
    {
      "epoch": 1.1888638073739655,
      "grad_norm": 0.9924535751342773,
      "learning_rate": 3.019187358916479e-05,
      "loss": 3.5127,
      "step": 3160
    },
    {
      "epoch": 1.1926260346124906,
      "grad_norm": 1.4105465412139893,
      "learning_rate": 3.0129169801856033e-05,
      "loss": 3.5388,
      "step": 3170
    },
    {
      "epoch": 1.1963882618510158,
      "grad_norm": 0.8987948894500732,
      "learning_rate": 3.0066466014547277e-05,
      "loss": 3.4143,
      "step": 3180
    },
    {
      "epoch": 1.200150489089541,
      "grad_norm": 1.0645662546157837,
      "learning_rate": 3.0003762227238525e-05,
      "loss": 3.4806,
      "step": 3190
    },
    {
      "epoch": 1.2039127163280663,
      "grad_norm": 1.0816744565963745,
      "learning_rate": 2.9941058439929775e-05,
      "loss": 3.4056,
      "step": 3200
    },
    {
      "epoch": 1.2076749435665914,
      "grad_norm": 1.0687170028686523,
      "learning_rate": 2.987835465262102e-05,
      "loss": 3.4813,
      "step": 3210
    },
    {
      "epoch": 1.2114371708051166,
      "grad_norm": 1.021997094154358,
      "learning_rate": 2.9815650865312267e-05,
      "loss": 3.4843,
      "step": 3220
    },
    {
      "epoch": 1.2151993980436417,
      "grad_norm": 0.9001084566116333,
      "learning_rate": 2.975294707800351e-05,
      "loss": 3.466,
      "step": 3230
    },
    {
      "epoch": 1.2189616252821671,
      "grad_norm": 1.08021080493927,
      "learning_rate": 2.969024329069476e-05,
      "loss": 3.5687,
      "step": 3240
    },
    {
      "epoch": 1.2227238525206923,
      "grad_norm": 1.2458466291427612,
      "learning_rate": 2.9627539503386003e-05,
      "loss": 3.4904,
      "step": 3250
    },
    {
      "epoch": 1.2264860797592174,
      "grad_norm": 1.1495380401611328,
      "learning_rate": 2.9564835716077253e-05,
      "loss": 3.5977,
      "step": 3260
    },
    {
      "epoch": 1.2302483069977426,
      "grad_norm": 1.2847532033920288,
      "learning_rate": 2.95021319287685e-05,
      "loss": 3.5033,
      "step": 3270
    },
    {
      "epoch": 1.234010534236268,
      "grad_norm": 1.1630924940109253,
      "learning_rate": 2.9439428141459745e-05,
      "loss": 3.5449,
      "step": 3280
    },
    {
      "epoch": 1.237772761474793,
      "grad_norm": 1.1902337074279785,
      "learning_rate": 2.9376724354150992e-05,
      "loss": 3.5,
      "step": 3290
    },
    {
      "epoch": 1.2415349887133182,
      "grad_norm": 1.1520452499389648,
      "learning_rate": 2.9314020566842237e-05,
      "loss": 3.4604,
      "step": 3300
    },
    {
      "epoch": 1.2452972159518434,
      "grad_norm": 1.0325952768325806,
      "learning_rate": 2.9251316779533484e-05,
      "loss": 3.5771,
      "step": 3310
    },
    {
      "epoch": 1.2490594431903688,
      "grad_norm": 1.107408881187439,
      "learning_rate": 2.9188612992224735e-05,
      "loss": 3.5069,
      "step": 3320
    },
    {
      "epoch": 1.252821670428894,
      "grad_norm": 1.1740527153015137,
      "learning_rate": 2.912590920491598e-05,
      "loss": 3.537,
      "step": 3330
    },
    {
      "epoch": 1.256583897667419,
      "grad_norm": 1.3765692710876465,
      "learning_rate": 2.9063205417607226e-05,
      "loss": 3.4825,
      "step": 3340
    },
    {
      "epoch": 1.2603461249059444,
      "grad_norm": 1.0027419328689575,
      "learning_rate": 2.900050163029847e-05,
      "loss": 3.4389,
      "step": 3350
    },
    {
      "epoch": 1.2641083521444696,
      "grad_norm": 0.9700008630752563,
      "learning_rate": 2.8937797842989718e-05,
      "loss": 3.4919,
      "step": 3360
    },
    {
      "epoch": 1.2678705793829947,
      "grad_norm": 1.1373180150985718,
      "learning_rate": 2.8875094055680962e-05,
      "loss": 3.5159,
      "step": 3370
    },
    {
      "epoch": 1.27163280662152,
      "grad_norm": 1.053520917892456,
      "learning_rate": 2.8812390268372213e-05,
      "loss": 3.5166,
      "step": 3380
    },
    {
      "epoch": 1.275395033860045,
      "grad_norm": 1.1794335842132568,
      "learning_rate": 2.874968648106346e-05,
      "loss": 3.4823,
      "step": 3390
    },
    {
      "epoch": 1.2791572610985704,
      "grad_norm": 1.0199145078659058,
      "learning_rate": 2.8686982693754704e-05,
      "loss": 3.4876,
      "step": 3400
    },
    {
      "epoch": 1.2829194883370956,
      "grad_norm": 0.9872565865516663,
      "learning_rate": 2.8624278906445952e-05,
      "loss": 3.4925,
      "step": 3410
    },
    {
      "epoch": 1.2866817155756207,
      "grad_norm": 0.9941700100898743,
      "learning_rate": 2.8561575119137196e-05,
      "loss": 3.4679,
      "step": 3420
    },
    {
      "epoch": 1.290443942814146,
      "grad_norm": 1.0779547691345215,
      "learning_rate": 2.849887133182844e-05,
      "loss": 3.4794,
      "step": 3430
    },
    {
      "epoch": 1.2942061700526712,
      "grad_norm": 1.334212064743042,
      "learning_rate": 2.8436167544519694e-05,
      "loss": 3.442,
      "step": 3440
    },
    {
      "epoch": 1.2979683972911964,
      "grad_norm": 1.1295722723007202,
      "learning_rate": 2.837346375721094e-05,
      "loss": 3.5002,
      "step": 3450
    },
    {
      "epoch": 1.3017306245297215,
      "grad_norm": 1.0376932621002197,
      "learning_rate": 2.8310759969902186e-05,
      "loss": 3.5534,
      "step": 3460
    },
    {
      "epoch": 1.3054928517682467,
      "grad_norm": 1.725684404373169,
      "learning_rate": 2.824805618259343e-05,
      "loss": 3.4692,
      "step": 3470
    },
    {
      "epoch": 1.309255079006772,
      "grad_norm": 1.396162986755371,
      "learning_rate": 2.8185352395284674e-05,
      "loss": 3.498,
      "step": 3480
    },
    {
      "epoch": 1.3130173062452972,
      "grad_norm": 1.1567076444625854,
      "learning_rate": 2.812264860797592e-05,
      "loss": 3.4757,
      "step": 3490
    },
    {
      "epoch": 1.3167795334838224,
      "grad_norm": 1.2100757360458374,
      "learning_rate": 2.8059944820667172e-05,
      "loss": 3.4058,
      "step": 3500
    },
    {
      "epoch": 1.3205417607223477,
      "grad_norm": 1.122543454170227,
      "learning_rate": 2.7997241033358416e-05,
      "loss": 3.4661,
      "step": 3510
    },
    {
      "epoch": 1.324303987960873,
      "grad_norm": 0.9767007231712341,
      "learning_rate": 2.7934537246049664e-05,
      "loss": 3.4991,
      "step": 3520
    },
    {
      "epoch": 1.328066215199398,
      "grad_norm": 1.0377113819122314,
      "learning_rate": 2.7871833458740908e-05,
      "loss": 3.622,
      "step": 3530
    },
    {
      "epoch": 1.3318284424379232,
      "grad_norm": 1.1883373260498047,
      "learning_rate": 2.7809129671432155e-05,
      "loss": 3.5499,
      "step": 3540
    },
    {
      "epoch": 1.3355906696764483,
      "grad_norm": 1.120260238647461,
      "learning_rate": 2.77464258841234e-05,
      "loss": 3.5183,
      "step": 3550
    },
    {
      "epoch": 1.3393528969149737,
      "grad_norm": 1.3257673978805542,
      "learning_rate": 2.768372209681465e-05,
      "loss": 3.548,
      "step": 3560
    },
    {
      "epoch": 1.3431151241534989,
      "grad_norm": 1.0588982105255127,
      "learning_rate": 2.7621018309505898e-05,
      "loss": 3.5022,
      "step": 3570
    },
    {
      "epoch": 1.346877351392024,
      "grad_norm": 1.112505316734314,
      "learning_rate": 2.7558314522197142e-05,
      "loss": 3.4844,
      "step": 3580
    },
    {
      "epoch": 1.3506395786305494,
      "grad_norm": 1.091801643371582,
      "learning_rate": 2.749561073488839e-05,
      "loss": 3.4819,
      "step": 3590
    },
    {
      "epoch": 1.3544018058690745,
      "grad_norm": 1.1188465356826782,
      "learning_rate": 2.7432906947579633e-05,
      "loss": 3.5894,
      "step": 3600
    },
    {
      "epoch": 1.3581640331075997,
      "grad_norm": 1.4177157878875732,
      "learning_rate": 2.737020316027088e-05,
      "loss": 3.4977,
      "step": 3610
    },
    {
      "epoch": 1.3619262603461249,
      "grad_norm": 1.0902236700057983,
      "learning_rate": 2.7307499372962132e-05,
      "loss": 3.5783,
      "step": 3620
    },
    {
      "epoch": 1.36568848758465,
      "grad_norm": 1.1646839380264282,
      "learning_rate": 2.7244795585653376e-05,
      "loss": 3.4307,
      "step": 3630
    },
    {
      "epoch": 1.3694507148231754,
      "grad_norm": 1.1345129013061523,
      "learning_rate": 2.7182091798344623e-05,
      "loss": 3.4359,
      "step": 3640
    },
    {
      "epoch": 1.3732129420617005,
      "grad_norm": 0.9708978533744812,
      "learning_rate": 2.7119388011035867e-05,
      "loss": 3.4271,
      "step": 3650
    },
    {
      "epoch": 1.3769751693002257,
      "grad_norm": 1.3934658765792847,
      "learning_rate": 2.7056684223727115e-05,
      "loss": 3.4986,
      "step": 3660
    },
    {
      "epoch": 1.380737396538751,
      "grad_norm": 1.257248878479004,
      "learning_rate": 2.699398043641836e-05,
      "loss": 3.4174,
      "step": 3670
    },
    {
      "epoch": 1.3844996237772762,
      "grad_norm": 1.0714174509048462,
      "learning_rate": 2.693127664910961e-05,
      "loss": 3.4672,
      "step": 3680
    },
    {
      "epoch": 1.3882618510158014,
      "grad_norm": 1.2102258205413818,
      "learning_rate": 2.6868572861800857e-05,
      "loss": 3.5309,
      "step": 3690
    },
    {
      "epoch": 1.3920240782543265,
      "grad_norm": 1.3626219034194946,
      "learning_rate": 2.68058690744921e-05,
      "loss": 3.5911,
      "step": 3700
    },
    {
      "epoch": 1.3957863054928517,
      "grad_norm": 1.009670615196228,
      "learning_rate": 2.674316528718335e-05,
      "loss": 3.5049,
      "step": 3710
    },
    {
      "epoch": 1.399548532731377,
      "grad_norm": 1.2331461906433105,
      "learning_rate": 2.6680461499874593e-05,
      "loss": 3.4463,
      "step": 3720
    },
    {
      "epoch": 1.4033107599699022,
      "grad_norm": 1.342833161354065,
      "learning_rate": 2.6617757712565837e-05,
      "loss": 3.4722,
      "step": 3730
    },
    {
      "epoch": 1.4070729872084273,
      "grad_norm": 1.5139364004135132,
      "learning_rate": 2.655505392525709e-05,
      "loss": 3.4766,
      "step": 3740
    },
    {
      "epoch": 1.4108352144469527,
      "grad_norm": 1.0162243843078613,
      "learning_rate": 2.6492350137948335e-05,
      "loss": 3.4691,
      "step": 3750
    },
    {
      "epoch": 1.4145974416854779,
      "grad_norm": 1.3286259174346924,
      "learning_rate": 2.642964635063958e-05,
      "loss": 3.4427,
      "step": 3760
    },
    {
      "epoch": 1.418359668924003,
      "grad_norm": 1.066456913948059,
      "learning_rate": 2.6366942563330827e-05,
      "loss": 3.5092,
      "step": 3770
    },
    {
      "epoch": 1.4221218961625282,
      "grad_norm": 1.3636916875839233,
      "learning_rate": 2.630423877602207e-05,
      "loss": 3.4175,
      "step": 3780
    },
    {
      "epoch": 1.4258841234010533,
      "grad_norm": 1.0644625425338745,
      "learning_rate": 2.624153498871332e-05,
      "loss": 3.5724,
      "step": 3790
    },
    {
      "epoch": 1.4296463506395787,
      "grad_norm": 1.4171934127807617,
      "learning_rate": 2.6178831201404562e-05,
      "loss": 3.4928,
      "step": 3800
    },
    {
      "epoch": 1.4334085778781038,
      "grad_norm": 1.111948013305664,
      "learning_rate": 2.6116127414095813e-05,
      "loss": 3.4922,
      "step": 3810
    },
    {
      "epoch": 1.437170805116629,
      "grad_norm": 1.221193790435791,
      "learning_rate": 2.605342362678706e-05,
      "loss": 3.5188,
      "step": 3820
    },
    {
      "epoch": 1.4409330323551544,
      "grad_norm": 1.1014306545257568,
      "learning_rate": 2.5990719839478305e-05,
      "loss": 3.4354,
      "step": 3830
    },
    {
      "epoch": 1.4446952595936795,
      "grad_norm": 1.3436806201934814,
      "learning_rate": 2.5928016052169552e-05,
      "loss": 3.5084,
      "step": 3840
    },
    {
      "epoch": 1.4484574868322047,
      "grad_norm": 1.1287124156951904,
      "learning_rate": 2.5865312264860796e-05,
      "loss": 3.5158,
      "step": 3850
    },
    {
      "epoch": 1.4522197140707298,
      "grad_norm": 1.1734097003936768,
      "learning_rate": 2.5802608477552044e-05,
      "loss": 3.4605,
      "step": 3860
    },
    {
      "epoch": 1.455981941309255,
      "grad_norm": 1.3530083894729614,
      "learning_rate": 2.5739904690243295e-05,
      "loss": 3.5012,
      "step": 3870
    },
    {
      "epoch": 1.4597441685477803,
      "grad_norm": 1.3990347385406494,
      "learning_rate": 2.567720090293454e-05,
      "loss": 3.5449,
      "step": 3880
    },
    {
      "epoch": 1.4635063957863055,
      "grad_norm": 1.0621274709701538,
      "learning_rate": 2.5614497115625786e-05,
      "loss": 3.4544,
      "step": 3890
    },
    {
      "epoch": 1.4672686230248306,
      "grad_norm": 1.2808302640914917,
      "learning_rate": 2.555179332831703e-05,
      "loss": 3.4909,
      "step": 3900
    },
    {
      "epoch": 1.471030850263356,
      "grad_norm": 1.216671109199524,
      "learning_rate": 2.5489089541008278e-05,
      "loss": 3.3556,
      "step": 3910
    },
    {
      "epoch": 1.4747930775018812,
      "grad_norm": 1.7798583507537842,
      "learning_rate": 2.5426385753699522e-05,
      "loss": 3.469,
      "step": 3920
    },
    {
      "epoch": 1.4785553047404063,
      "grad_norm": 0.9717420339584351,
      "learning_rate": 2.5363681966390773e-05,
      "loss": 3.4799,
      "step": 3930
    },
    {
      "epoch": 1.4823175319789315,
      "grad_norm": 1.2746102809906006,
      "learning_rate": 2.530097817908202e-05,
      "loss": 3.5559,
      "step": 3940
    },
    {
      "epoch": 1.4860797592174566,
      "grad_norm": 1.0623009204864502,
      "learning_rate": 2.5238274391773264e-05,
      "loss": 3.4896,
      "step": 3950
    },
    {
      "epoch": 1.489841986455982,
      "grad_norm": 1.2883058786392212,
      "learning_rate": 2.517557060446451e-05,
      "loss": 3.4747,
      "step": 3960
    },
    {
      "epoch": 1.4936042136945071,
      "grad_norm": 1.3218401670455933,
      "learning_rate": 2.5112866817155756e-05,
      "loss": 3.5183,
      "step": 3970
    },
    {
      "epoch": 1.4973664409330323,
      "grad_norm": 1.2268532514572144,
      "learning_rate": 2.5050163029847e-05,
      "loss": 3.4725,
      "step": 3980
    },
    {
      "epoch": 1.5011286681715577,
      "grad_norm": 1.1577805280685425,
      "learning_rate": 2.498745924253825e-05,
      "loss": 3.474,
      "step": 3990
    },
    {
      "epoch": 1.5048908954100828,
      "grad_norm": 1.3232795000076294,
      "learning_rate": 2.4924755455229498e-05,
      "loss": 3.4986,
      "step": 4000
    },
    {
      "epoch": 1.508653122648608,
      "grad_norm": 1.1762654781341553,
      "learning_rate": 2.4862051667920742e-05,
      "loss": 3.4523,
      "step": 4010
    },
    {
      "epoch": 1.5124153498871333,
      "grad_norm": 1.1656478643417358,
      "learning_rate": 2.479934788061199e-05,
      "loss": 3.5718,
      "step": 4020
    },
    {
      "epoch": 1.5161775771256583,
      "grad_norm": 1.3014798164367676,
      "learning_rate": 2.4736644093303237e-05,
      "loss": 3.4585,
      "step": 4030
    },
    {
      "epoch": 1.5199398043641836,
      "grad_norm": 1.544368863105774,
      "learning_rate": 2.4673940305994485e-05,
      "loss": 3.4755,
      "step": 4040
    },
    {
      "epoch": 1.5237020316027088,
      "grad_norm": 0.9902254343032837,
      "learning_rate": 2.461123651868573e-05,
      "loss": 3.4792,
      "step": 4050
    },
    {
      "epoch": 1.527464258841234,
      "grad_norm": 1.2328579425811768,
      "learning_rate": 2.4548532731376976e-05,
      "loss": 3.4512,
      "step": 4060
    },
    {
      "epoch": 1.5312264860797593,
      "grad_norm": 1.286853313446045,
      "learning_rate": 2.4485828944068224e-05,
      "loss": 3.4662,
      "step": 4070
    },
    {
      "epoch": 1.5349887133182845,
      "grad_norm": 1.1475938558578491,
      "learning_rate": 2.4423125156759468e-05,
      "loss": 3.486,
      "step": 4080
    },
    {
      "epoch": 1.5387509405568096,
      "grad_norm": 1.250938892364502,
      "learning_rate": 2.436042136945072e-05,
      "loss": 3.5015,
      "step": 4090
    },
    {
      "epoch": 1.542513167795335,
      "grad_norm": 1.2360332012176514,
      "learning_rate": 2.4297717582141963e-05,
      "loss": 3.4531,
      "step": 4100
    },
    {
      "epoch": 1.54627539503386,
      "grad_norm": 1.267254114151001,
      "learning_rate": 2.423501379483321e-05,
      "loss": 3.5044,
      "step": 4110
    },
    {
      "epoch": 1.5500376222723853,
      "grad_norm": 1.0931665897369385,
      "learning_rate": 2.4172310007524458e-05,
      "loss": 3.5193,
      "step": 4120
    },
    {
      "epoch": 1.5537998495109104,
      "grad_norm": 1.0897499322891235,
      "learning_rate": 2.41096062202157e-05,
      "loss": 3.5398,
      "step": 4130
    },
    {
      "epoch": 1.5575620767494356,
      "grad_norm": 1.080837607383728,
      "learning_rate": 2.404690243290695e-05,
      "loss": 3.4991,
      "step": 4140
    },
    {
      "epoch": 1.561324303987961,
      "grad_norm": 1.1213926076889038,
      "learning_rate": 2.3984198645598197e-05,
      "loss": 3.4498,
      "step": 4150
    },
    {
      "epoch": 1.565086531226486,
      "grad_norm": 1.1491477489471436,
      "learning_rate": 2.392149485828944e-05,
      "loss": 3.4574,
      "step": 4160
    },
    {
      "epoch": 1.5688487584650113,
      "grad_norm": 1.4429103136062622,
      "learning_rate": 2.3858791070980688e-05,
      "loss": 3.4166,
      "step": 4170
    },
    {
      "epoch": 1.5726109857035366,
      "grad_norm": 1.2330348491668701,
      "learning_rate": 2.3796087283671936e-05,
      "loss": 3.4798,
      "step": 4180
    },
    {
      "epoch": 1.5763732129420616,
      "grad_norm": 1.0309523344039917,
      "learning_rate": 2.3733383496363183e-05,
      "loss": 3.3763,
      "step": 4190
    },
    {
      "epoch": 1.580135440180587,
      "grad_norm": 1.0705817937850952,
      "learning_rate": 2.3670679709054427e-05,
      "loss": 3.4778,
      "step": 4200
    },
    {
      "epoch": 1.583897667419112,
      "grad_norm": 1.0150671005249023,
      "learning_rate": 2.3607975921745675e-05,
      "loss": 3.4665,
      "step": 4210
    },
    {
      "epoch": 1.5876598946576372,
      "grad_norm": 1.1203830242156982,
      "learning_rate": 2.3545272134436922e-05,
      "loss": 3.4722,
      "step": 4220
    },
    {
      "epoch": 1.5914221218961626,
      "grad_norm": 1.0719436407089233,
      "learning_rate": 2.3482568347128166e-05,
      "loss": 3.3779,
      "step": 4230
    },
    {
      "epoch": 1.5951843491346878,
      "grad_norm": 1.5565211772918701,
      "learning_rate": 2.3419864559819417e-05,
      "loss": 3.4055,
      "step": 4240
    },
    {
      "epoch": 1.598946576373213,
      "grad_norm": 1.3506743907928467,
      "learning_rate": 2.335716077251066e-05,
      "loss": 3.4826,
      "step": 4250
    },
    {
      "epoch": 1.6027088036117383,
      "grad_norm": 1.2327021360397339,
      "learning_rate": 2.3294456985201905e-05,
      "loss": 3.4532,
      "step": 4260
    },
    {
      "epoch": 1.6064710308502632,
      "grad_norm": 0.9407109618186951,
      "learning_rate": 2.3231753197893156e-05,
      "loss": 3.5426,
      "step": 4270
    },
    {
      "epoch": 1.6102332580887886,
      "grad_norm": 1.2242997884750366,
      "learning_rate": 2.31690494105844e-05,
      "loss": 3.4607,
      "step": 4280
    },
    {
      "epoch": 1.6139954853273137,
      "grad_norm": 1.203769326210022,
      "learning_rate": 2.3106345623275648e-05,
      "loss": 3.4692,
      "step": 4290
    },
    {
      "epoch": 1.617757712565839,
      "grad_norm": 0.9788504242897034,
      "learning_rate": 2.3043641835966895e-05,
      "loss": 3.481,
      "step": 4300
    },
    {
      "epoch": 1.6215199398043643,
      "grad_norm": 1.583181381225586,
      "learning_rate": 2.298093804865814e-05,
      "loss": 3.411,
      "step": 4310
    },
    {
      "epoch": 1.6252821670428894,
      "grad_norm": 1.2225992679595947,
      "learning_rate": 2.2918234261349387e-05,
      "loss": 3.4779,
      "step": 4320
    },
    {
      "epoch": 1.6290443942814146,
      "grad_norm": 1.1734883785247803,
      "learning_rate": 2.2855530474040634e-05,
      "loss": 3.5185,
      "step": 4330
    },
    {
      "epoch": 1.63280662151994,
      "grad_norm": 1.403942584991455,
      "learning_rate": 2.279282668673188e-05,
      "loss": 3.5163,
      "step": 4340
    },
    {
      "epoch": 1.6365688487584649,
      "grad_norm": 1.2983886003494263,
      "learning_rate": 2.2730122899423126e-05,
      "loss": 3.4752,
      "step": 4350
    },
    {
      "epoch": 1.6403310759969902,
      "grad_norm": 1.0654596090316772,
      "learning_rate": 2.2667419112114373e-05,
      "loss": 3.4743,
      "step": 4360
    },
    {
      "epoch": 1.6440933032355154,
      "grad_norm": 1.0332430601119995,
      "learning_rate": 2.260471532480562e-05,
      "loss": 3.4095,
      "step": 4370
    },
    {
      "epoch": 1.6478555304740405,
      "grad_norm": 1.00578773021698,
      "learning_rate": 2.2542011537496865e-05,
      "loss": 3.4347,
      "step": 4380
    },
    {
      "epoch": 1.651617757712566,
      "grad_norm": 1.0802565813064575,
      "learning_rate": 2.2479307750188112e-05,
      "loss": 3.3989,
      "step": 4390
    },
    {
      "epoch": 1.655379984951091,
      "grad_norm": 1.0244981050491333,
      "learning_rate": 2.241660396287936e-05,
      "loss": 3.4459,
      "step": 4400
    },
    {
      "epoch": 1.6591422121896162,
      "grad_norm": 1.6471412181854248,
      "learning_rate": 2.2353900175570604e-05,
      "loss": 3.4974,
      "step": 4410
    },
    {
      "epoch": 1.6629044394281416,
      "grad_norm": 1.5014559030532837,
      "learning_rate": 2.229119638826185e-05,
      "loss": 3.5381,
      "step": 4420
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.0445712804794312,
      "learning_rate": 2.22284926009531e-05,
      "loss": 3.5093,
      "step": 4430
    },
    {
      "epoch": 1.670428893905192,
      "grad_norm": 1.0067776441574097,
      "learning_rate": 2.2165788813644346e-05,
      "loss": 3.5229,
      "step": 4440
    },
    {
      "epoch": 1.674191121143717,
      "grad_norm": 1.3112086057662964,
      "learning_rate": 2.210308502633559e-05,
      "loss": 3.6125,
      "step": 4450
    },
    {
      "epoch": 1.6779533483822422,
      "grad_norm": 1.8026875257492065,
      "learning_rate": 2.2040381239026838e-05,
      "loss": 3.5149,
      "step": 4460
    },
    {
      "epoch": 1.6817155756207676,
      "grad_norm": 1.0210753679275513,
      "learning_rate": 2.1977677451718085e-05,
      "loss": 3.4058,
      "step": 4470
    },
    {
      "epoch": 1.6854778028592927,
      "grad_norm": 1.245918869972229,
      "learning_rate": 2.191497366440933e-05,
      "loss": 3.4968,
      "step": 4480
    },
    {
      "epoch": 1.6892400300978179,
      "grad_norm": 1.176560401916504,
      "learning_rate": 2.185226987710058e-05,
      "loss": 3.5661,
      "step": 4490
    },
    {
      "epoch": 1.6930022573363432,
      "grad_norm": 1.1185671091079712,
      "learning_rate": 2.1789566089791824e-05,
      "loss": 3.4847,
      "step": 4500
    },
    {
      "epoch": 1.6967644845748682,
      "grad_norm": 1.209158182144165,
      "learning_rate": 2.1726862302483068e-05,
      "loss": 3.5585,
      "step": 4510
    },
    {
      "epoch": 1.7005267118133935,
      "grad_norm": 1.0913736820220947,
      "learning_rate": 2.166415851517432e-05,
      "loss": 3.4378,
      "step": 4520
    },
    {
      "epoch": 1.7042889390519187,
      "grad_norm": 1.2680281400680542,
      "learning_rate": 2.1601454727865563e-05,
      "loss": 3.5515,
      "step": 4530
    },
    {
      "epoch": 1.7080511662904438,
      "grad_norm": 1.0546492338180542,
      "learning_rate": 2.153875094055681e-05,
      "loss": 3.5199,
      "step": 4540
    },
    {
      "epoch": 1.7118133935289692,
      "grad_norm": 1.2555551528930664,
      "learning_rate": 2.1476047153248058e-05,
      "loss": 3.5642,
      "step": 4550
    },
    {
      "epoch": 1.7155756207674944,
      "grad_norm": 1.240992546081543,
      "learning_rate": 2.1413343365939302e-05,
      "loss": 3.4691,
      "step": 4560
    },
    {
      "epoch": 1.7193378480060195,
      "grad_norm": 1.1448962688446045,
      "learning_rate": 2.135063957863055e-05,
      "loss": 3.4707,
      "step": 4570
    },
    {
      "epoch": 1.723100075244545,
      "grad_norm": 1.3551859855651855,
      "learning_rate": 2.1287935791321797e-05,
      "loss": 3.438,
      "step": 4580
    },
    {
      "epoch": 1.7268623024830698,
      "grad_norm": 1.1565967798233032,
      "learning_rate": 2.1225232004013044e-05,
      "loss": 3.4734,
      "step": 4590
    },
    {
      "epoch": 1.7306245297215952,
      "grad_norm": 1.2957837581634521,
      "learning_rate": 2.116252821670429e-05,
      "loss": 3.478,
      "step": 4600
    },
    {
      "epoch": 1.7343867569601203,
      "grad_norm": 1.1315648555755615,
      "learning_rate": 2.1099824429395536e-05,
      "loss": 3.4797,
      "step": 4610
    },
    {
      "epoch": 1.7381489841986455,
      "grad_norm": 1.221082329750061,
      "learning_rate": 2.1037120642086783e-05,
      "loss": 3.5301,
      "step": 4620
    },
    {
      "epoch": 1.7419112114371709,
      "grad_norm": 1.4692485332489014,
      "learning_rate": 2.0974416854778028e-05,
      "loss": 3.3871,
      "step": 4630
    },
    {
      "epoch": 1.745673438675696,
      "grad_norm": 1.0550432205200195,
      "learning_rate": 2.091171306746928e-05,
      "loss": 3.443,
      "step": 4640
    },
    {
      "epoch": 1.7494356659142212,
      "grad_norm": 1.3600552082061768,
      "learning_rate": 2.0849009280160522e-05,
      "loss": 3.4985,
      "step": 4650
    },
    {
      "epoch": 1.7531978931527465,
      "grad_norm": 1.221132755279541,
      "learning_rate": 2.0786305492851767e-05,
      "loss": 3.4232,
      "step": 4660
    },
    {
      "epoch": 1.7569601203912715,
      "grad_norm": 1.2049381732940674,
      "learning_rate": 2.0723601705543017e-05,
      "loss": 3.479,
      "step": 4670
    },
    {
      "epoch": 1.7607223476297968,
      "grad_norm": 1.1224510669708252,
      "learning_rate": 2.066089791823426e-05,
      "loss": 3.502,
      "step": 4680
    },
    {
      "epoch": 1.764484574868322,
      "grad_norm": 1.0833863019943237,
      "learning_rate": 2.059819413092551e-05,
      "loss": 3.4807,
      "step": 4690
    },
    {
      "epoch": 1.7682468021068471,
      "grad_norm": 1.1343131065368652,
      "learning_rate": 2.0535490343616756e-05,
      "loss": 3.4494,
      "step": 4700
    },
    {
      "epoch": 1.7720090293453725,
      "grad_norm": 1.1535990238189697,
      "learning_rate": 2.0472786556308e-05,
      "loss": 3.5023,
      "step": 4710
    },
    {
      "epoch": 1.7757712565838977,
      "grad_norm": 1.053032636642456,
      "learning_rate": 2.0410082768999248e-05,
      "loss": 3.4195,
      "step": 4720
    },
    {
      "epoch": 1.7795334838224228,
      "grad_norm": 1.516353964805603,
      "learning_rate": 2.0347378981690495e-05,
      "loss": 3.5142,
      "step": 4730
    },
    {
      "epoch": 1.7832957110609482,
      "grad_norm": 1.075690507888794,
      "learning_rate": 2.0284675194381743e-05,
      "loss": 3.489,
      "step": 4740
    },
    {
      "epoch": 1.7870579382994731,
      "grad_norm": 1.0804102420806885,
      "learning_rate": 2.0221971407072987e-05,
      "loss": 3.5636,
      "step": 4750
    },
    {
      "epoch": 1.7908201655379985,
      "grad_norm": 1.3358060121536255,
      "learning_rate": 2.0159267619764234e-05,
      "loss": 3.5574,
      "step": 4760
    },
    {
      "epoch": 1.7945823927765236,
      "grad_norm": 1.1712117195129395,
      "learning_rate": 2.0096563832455482e-05,
      "loss": 3.5038,
      "step": 4770
    },
    {
      "epoch": 1.7983446200150488,
      "grad_norm": 1.2839775085449219,
      "learning_rate": 2.0033860045146726e-05,
      "loss": 3.4929,
      "step": 4780
    },
    {
      "epoch": 1.8021068472535742,
      "grad_norm": 1.2128336429595947,
      "learning_rate": 1.9971156257837977e-05,
      "loss": 3.5309,
      "step": 4790
    },
    {
      "epoch": 1.8058690744920993,
      "grad_norm": 1.2131930589675903,
      "learning_rate": 1.990845247052922e-05,
      "loss": 3.4979,
      "step": 4800
    },
    {
      "epoch": 1.8096313017306245,
      "grad_norm": 1.4555233716964722,
      "learning_rate": 1.9845748683220465e-05,
      "loss": 3.5113,
      "step": 4810
    },
    {
      "epoch": 1.8133935289691498,
      "grad_norm": 1.054075002670288,
      "learning_rate": 1.9783044895911716e-05,
      "loss": 3.489,
      "step": 4820
    },
    {
      "epoch": 1.8171557562076748,
      "grad_norm": 1.0844975709915161,
      "learning_rate": 1.972034110860296e-05,
      "loss": 3.3681,
      "step": 4830
    },
    {
      "epoch": 1.8209179834462002,
      "grad_norm": 1.3383485078811646,
      "learning_rate": 1.9657637321294207e-05,
      "loss": 3.4616,
      "step": 4840
    },
    {
      "epoch": 1.8246802106847255,
      "grad_norm": 1.2105718851089478,
      "learning_rate": 1.9594933533985455e-05,
      "loss": 3.4853,
      "step": 4850
    },
    {
      "epoch": 1.8284424379232505,
      "grad_norm": 1.0026986598968506,
      "learning_rate": 1.95322297466767e-05,
      "loss": 3.4862,
      "step": 4860
    },
    {
      "epoch": 1.8322046651617758,
      "grad_norm": 1.2902777194976807,
      "learning_rate": 1.9469525959367946e-05,
      "loss": 3.5066,
      "step": 4870
    },
    {
      "epoch": 1.835966892400301,
      "grad_norm": 1.4141041040420532,
      "learning_rate": 1.9406822172059194e-05,
      "loss": 3.4749,
      "step": 4880
    },
    {
      "epoch": 1.8397291196388261,
      "grad_norm": 1.1394177675247192,
      "learning_rate": 1.934411838475044e-05,
      "loss": 3.4098,
      "step": 4890
    },
    {
      "epoch": 1.8434913468773515,
      "grad_norm": 1.1020768880844116,
      "learning_rate": 1.9281414597441685e-05,
      "loss": 3.4217,
      "step": 4900
    },
    {
      "epoch": 1.8472535741158767,
      "grad_norm": 1.1133384704589844,
      "learning_rate": 1.9218710810132933e-05,
      "loss": 3.4562,
      "step": 4910
    },
    {
      "epoch": 1.8510158013544018,
      "grad_norm": 1.2956539392471313,
      "learning_rate": 1.915600702282418e-05,
      "loss": 3.5143,
      "step": 4920
    },
    {
      "epoch": 1.8547780285929272,
      "grad_norm": 1.359546184539795,
      "learning_rate": 1.9093303235515424e-05,
      "loss": 3.5394,
      "step": 4930
    },
    {
      "epoch": 1.858540255831452,
      "grad_norm": 1.174655556678772,
      "learning_rate": 1.9030599448206672e-05,
      "loss": 3.586,
      "step": 4940
    },
    {
      "epoch": 1.8623024830699775,
      "grad_norm": 1.2297694683074951,
      "learning_rate": 1.896789566089792e-05,
      "loss": 3.468,
      "step": 4950
    },
    {
      "epoch": 1.8660647103085026,
      "grad_norm": 1.2227197885513306,
      "learning_rate": 1.8905191873589163e-05,
      "loss": 3.4693,
      "step": 4960
    },
    {
      "epoch": 1.8698269375470278,
      "grad_norm": 1.1436625719070435,
      "learning_rate": 1.8842488086280414e-05,
      "loss": 3.5348,
      "step": 4970
    },
    {
      "epoch": 1.8735891647855532,
      "grad_norm": 1.0110512971878052,
      "learning_rate": 1.877978429897166e-05,
      "loss": 3.4912,
      "step": 4980
    },
    {
      "epoch": 1.8773513920240783,
      "grad_norm": 1.253039836883545,
      "learning_rate": 1.8717080511662906e-05,
      "loss": 3.4689,
      "step": 4990
    },
    {
      "epoch": 1.8811136192626035,
      "grad_norm": 1.486706256866455,
      "learning_rate": 1.8654376724354153e-05,
      "loss": 3.4677,
      "step": 5000
    },
    {
      "epoch": 1.8848758465011288,
      "grad_norm": 0.9960825443267822,
      "learning_rate": 1.8591672937045397e-05,
      "loss": 3.3797,
      "step": 5010
    },
    {
      "epoch": 1.8886380737396538,
      "grad_norm": 1.3020761013031006,
      "learning_rate": 1.8528969149736645e-05,
      "loss": 3.4359,
      "step": 5020
    },
    {
      "epoch": 1.8924003009781791,
      "grad_norm": 1.1756805181503296,
      "learning_rate": 1.8466265362427892e-05,
      "loss": 3.476,
      "step": 5030
    },
    {
      "epoch": 1.8961625282167043,
      "grad_norm": 1.1984848976135254,
      "learning_rate": 1.840356157511914e-05,
      "loss": 3.467,
      "step": 5040
    },
    {
      "epoch": 1.8999247554552294,
      "grad_norm": 1.2393345832824707,
      "learning_rate": 1.8340857787810384e-05,
      "loss": 3.5608,
      "step": 5050
    },
    {
      "epoch": 1.9036869826937548,
      "grad_norm": 1.2963663339614868,
      "learning_rate": 1.827815400050163e-05,
      "loss": 3.5327,
      "step": 5060
    },
    {
      "epoch": 1.90744920993228,
      "grad_norm": 1.2070012092590332,
      "learning_rate": 1.821545021319288e-05,
      "loss": 3.4983,
      "step": 5070
    },
    {
      "epoch": 1.911211437170805,
      "grad_norm": 1.1398409605026245,
      "learning_rate": 1.8152746425884123e-05,
      "loss": 3.4828,
      "step": 5080
    },
    {
      "epoch": 1.9149736644093305,
      "grad_norm": 1.1215174198150635,
      "learning_rate": 1.809004263857537e-05,
      "loss": 3.4598,
      "step": 5090
    },
    {
      "epoch": 1.9187358916478554,
      "grad_norm": 2.1581718921661377,
      "learning_rate": 1.8027338851266618e-05,
      "loss": 3.5136,
      "step": 5100
    },
    {
      "epoch": 1.9224981188863808,
      "grad_norm": 1.181700348854065,
      "learning_rate": 1.7964635063957862e-05,
      "loss": 3.4735,
      "step": 5110
    },
    {
      "epoch": 1.926260346124906,
      "grad_norm": 1.2692521810531616,
      "learning_rate": 1.7901931276649113e-05,
      "loss": 3.4764,
      "step": 5120
    },
    {
      "epoch": 1.930022573363431,
      "grad_norm": 1.1465026140213013,
      "learning_rate": 1.7839227489340357e-05,
      "loss": 3.4524,
      "step": 5130
    },
    {
      "epoch": 1.9337848006019565,
      "grad_norm": 1.0249346494674683,
      "learning_rate": 1.7776523702031604e-05,
      "loss": 3.4965,
      "step": 5140
    },
    {
      "epoch": 1.9375470278404816,
      "grad_norm": 1.1161609888076782,
      "learning_rate": 1.7713819914722852e-05,
      "loss": 3.504,
      "step": 5150
    },
    {
      "epoch": 1.9413092550790068,
      "grad_norm": 1.2439457178115845,
      "learning_rate": 1.7651116127414096e-05,
      "loss": 3.5629,
      "step": 5160
    },
    {
      "epoch": 1.9450714823175321,
      "grad_norm": 1.3276712894439697,
      "learning_rate": 1.7588412340105343e-05,
      "loss": 3.4578,
      "step": 5170
    },
    {
      "epoch": 1.948833709556057,
      "grad_norm": 1.2804439067840576,
      "learning_rate": 1.752570855279659e-05,
      "loss": 3.4403,
      "step": 5180
    },
    {
      "epoch": 1.9525959367945824,
      "grad_norm": 1.3630691766738892,
      "learning_rate": 1.7463004765487835e-05,
      "loss": 3.4945,
      "step": 5190
    },
    {
      "epoch": 1.9563581640331076,
      "grad_norm": 1.33404541015625,
      "learning_rate": 1.7400300978179082e-05,
      "loss": 3.4853,
      "step": 5200
    },
    {
      "epoch": 1.9601203912716327,
      "grad_norm": 1.1535013914108276,
      "learning_rate": 1.733759719087033e-05,
      "loss": 3.3772,
      "step": 5210
    },
    {
      "epoch": 1.963882618510158,
      "grad_norm": 1.7687352895736694,
      "learning_rate": 1.7274893403561577e-05,
      "loss": 3.5144,
      "step": 5220
    },
    {
      "epoch": 1.9676448457486833,
      "grad_norm": 1.0045857429504395,
      "learning_rate": 1.721218961625282e-05,
      "loss": 3.4437,
      "step": 5230
    },
    {
      "epoch": 1.9714070729872084,
      "grad_norm": 1.191218376159668,
      "learning_rate": 1.714948582894407e-05,
      "loss": 3.4442,
      "step": 5240
    },
    {
      "epoch": 1.9751693002257338,
      "grad_norm": 1.1810297966003418,
      "learning_rate": 1.7086782041635316e-05,
      "loss": 3.5008,
      "step": 5250
    },
    {
      "epoch": 1.9789315274642587,
      "grad_norm": 1.159781813621521,
      "learning_rate": 1.702407825432656e-05,
      "loss": 3.5269,
      "step": 5260
    },
    {
      "epoch": 1.982693754702784,
      "grad_norm": 1.2171871662139893,
      "learning_rate": 1.696137446701781e-05,
      "loss": 3.4023,
      "step": 5270
    },
    {
      "epoch": 1.9864559819413092,
      "grad_norm": 1.2943884134292603,
      "learning_rate": 1.6898670679709055e-05,
      "loss": 3.5695,
      "step": 5280
    },
    {
      "epoch": 1.9902182091798344,
      "grad_norm": 1.337739109992981,
      "learning_rate": 1.6835966892400303e-05,
      "loss": 3.4041,
      "step": 5290
    },
    {
      "epoch": 1.9939804364183598,
      "grad_norm": 1.3578749895095825,
      "learning_rate": 1.677326310509155e-05,
      "loss": 3.4115,
      "step": 5300
    },
    {
      "epoch": 1.997742663656885,
      "grad_norm": 1.1544981002807617,
      "learning_rate": 1.6710559317782794e-05,
      "loss": 3.5169,
      "step": 5310
    },
    {
      "epoch": 2.00150489089541,
      "grad_norm": 1.0123072862625122,
      "learning_rate": 1.6647855530474042e-05,
      "loss": 3.4733,
      "step": 5320
    },
    {
      "epoch": 2.0052671181339354,
      "grad_norm": 1.137589931488037,
      "learning_rate": 1.658515174316529e-05,
      "loss": 3.4875,
      "step": 5330
    },
    {
      "epoch": 2.0090293453724604,
      "grad_norm": 1.3351885080337524,
      "learning_rate": 1.6522447955856533e-05,
      "loss": 3.5402,
      "step": 5340
    },
    {
      "epoch": 2.0127915726109857,
      "grad_norm": 1.3897703886032104,
      "learning_rate": 1.645974416854778e-05,
      "loss": 3.4735,
      "step": 5350
    },
    {
      "epoch": 2.016553799849511,
      "grad_norm": 1.3981822729110718,
      "learning_rate": 1.6397040381239028e-05,
      "loss": 3.5556,
      "step": 5360
    },
    {
      "epoch": 2.020316027088036,
      "grad_norm": 1.290504813194275,
      "learning_rate": 1.6334336593930276e-05,
      "loss": 3.527,
      "step": 5370
    },
    {
      "epoch": 2.0240782543265614,
      "grad_norm": 1.3067694902420044,
      "learning_rate": 1.627163280662152e-05,
      "loss": 3.4377,
      "step": 5380
    },
    {
      "epoch": 2.0278404815650863,
      "grad_norm": 1.3946138620376587,
      "learning_rate": 1.6208929019312767e-05,
      "loss": 3.4567,
      "step": 5390
    },
    {
      "epoch": 2.0316027088036117,
      "grad_norm": 1.120735764503479,
      "learning_rate": 1.6146225232004015e-05,
      "loss": 3.4645,
      "step": 5400
    },
    {
      "epoch": 2.035364936042137,
      "grad_norm": 1.4166408777236938,
      "learning_rate": 1.608352144469526e-05,
      "loss": 3.4723,
      "step": 5410
    },
    {
      "epoch": 2.039127163280662,
      "grad_norm": 1.2195645570755005,
      "learning_rate": 1.602081765738651e-05,
      "loss": 3.421,
      "step": 5420
    },
    {
      "epoch": 2.0428893905191874,
      "grad_norm": 1.0752092599868774,
      "learning_rate": 1.5958113870077754e-05,
      "loss": 3.4438,
      "step": 5430
    },
    {
      "epoch": 2.0466516177577128,
      "grad_norm": 1.2271747589111328,
      "learning_rate": 1.5895410082769e-05,
      "loss": 3.5129,
      "step": 5440
    },
    {
      "epoch": 2.0504138449962377,
      "grad_norm": 1.1349667310714722,
      "learning_rate": 1.583270629546025e-05,
      "loss": 3.5416,
      "step": 5450
    },
    {
      "epoch": 2.054176072234763,
      "grad_norm": 1.212145447731018,
      "learning_rate": 1.5770002508151493e-05,
      "loss": 3.4684,
      "step": 5460
    },
    {
      "epoch": 2.057938299473288,
      "grad_norm": 1.0999971628189087,
      "learning_rate": 1.570729872084274e-05,
      "loss": 3.5475,
      "step": 5470
    },
    {
      "epoch": 2.0617005267118134,
      "grad_norm": 1.1252667903900146,
      "learning_rate": 1.5644594933533988e-05,
      "loss": 3.3944,
      "step": 5480
    },
    {
      "epoch": 2.0654627539503387,
      "grad_norm": 1.1128665208816528,
      "learning_rate": 1.558189114622523e-05,
      "loss": 3.4028,
      "step": 5490
    },
    {
      "epoch": 2.0692249811888637,
      "grad_norm": 1.5918139219284058,
      "learning_rate": 1.551918735891648e-05,
      "loss": 3.6426,
      "step": 5500
    },
    {
      "epoch": 2.072987208427389,
      "grad_norm": 1.1069611310958862,
      "learning_rate": 1.5456483571607727e-05,
      "loss": 3.5893,
      "step": 5510
    },
    {
      "epoch": 2.0767494356659144,
      "grad_norm": 1.534575343132019,
      "learning_rate": 1.5393779784298974e-05,
      "loss": 3.4703,
      "step": 5520
    },
    {
      "epoch": 2.0805116629044393,
      "grad_norm": 1.2348281145095825,
      "learning_rate": 1.5331075996990218e-05,
      "loss": 3.4772,
      "step": 5530
    },
    {
      "epoch": 2.0842738901429647,
      "grad_norm": 1.252854347229004,
      "learning_rate": 1.5268372209681466e-05,
      "loss": 3.53,
      "step": 5540
    },
    {
      "epoch": 2.0880361173814896,
      "grad_norm": 1.2002402544021606,
      "learning_rate": 1.5205668422372713e-05,
      "loss": 3.47,
      "step": 5550
    },
    {
      "epoch": 2.091798344620015,
      "grad_norm": 1.3978182077407837,
      "learning_rate": 1.5142964635063959e-05,
      "loss": 3.5399,
      "step": 5560
    },
    {
      "epoch": 2.0955605718585404,
      "grad_norm": 1.0972472429275513,
      "learning_rate": 1.5080260847755203e-05,
      "loss": 3.4357,
      "step": 5570
    },
    {
      "epoch": 2.0993227990970653,
      "grad_norm": 1.2397969961166382,
      "learning_rate": 1.5017557060446452e-05,
      "loss": 3.4772,
      "step": 5580
    },
    {
      "epoch": 2.1030850263355907,
      "grad_norm": 2.2345244884490967,
      "learning_rate": 1.4954853273137698e-05,
      "loss": 3.4499,
      "step": 5590
    },
    {
      "epoch": 2.106847253574116,
      "grad_norm": 1.0876151323318481,
      "learning_rate": 1.4892149485828944e-05,
      "loss": 3.4028,
      "step": 5600
    },
    {
      "epoch": 2.110609480812641,
      "grad_norm": 1.1441007852554321,
      "learning_rate": 1.4829445698520191e-05,
      "loss": 3.5045,
      "step": 5610
    },
    {
      "epoch": 2.1143717080511664,
      "grad_norm": 1.1609491109848022,
      "learning_rate": 1.4766741911211437e-05,
      "loss": 3.4804,
      "step": 5620
    },
    {
      "epoch": 2.1181339352896913,
      "grad_norm": 1.285549521446228,
      "learning_rate": 1.4704038123902683e-05,
      "loss": 3.5171,
      "step": 5630
    },
    {
      "epoch": 2.1218961625282167,
      "grad_norm": 1.3508579730987549,
      "learning_rate": 1.4641334336593932e-05,
      "loss": 3.4083,
      "step": 5640
    },
    {
      "epoch": 2.125658389766742,
      "grad_norm": 1.5759961605072021,
      "learning_rate": 1.4578630549285178e-05,
      "loss": 3.4218,
      "step": 5650
    },
    {
      "epoch": 2.129420617005267,
      "grad_norm": 1.1843584775924683,
      "learning_rate": 1.4515926761976423e-05,
      "loss": 3.5415,
      "step": 5660
    },
    {
      "epoch": 2.1331828442437923,
      "grad_norm": 1.1466273069381714,
      "learning_rate": 1.445322297466767e-05,
      "loss": 3.4576,
      "step": 5670
    },
    {
      "epoch": 2.1369450714823177,
      "grad_norm": 1.040768027305603,
      "learning_rate": 1.4390519187358917e-05,
      "loss": 3.5032,
      "step": 5680
    },
    {
      "epoch": 2.1407072987208426,
      "grad_norm": 1.3191149234771729,
      "learning_rate": 1.4327815400050162e-05,
      "loss": 3.4993,
      "step": 5690
    },
    {
      "epoch": 2.144469525959368,
      "grad_norm": 1.4548739194869995,
      "learning_rate": 1.4265111612741412e-05,
      "loss": 3.5633,
      "step": 5700
    },
    {
      "epoch": 2.148231753197893,
      "grad_norm": 1.134450912475586,
      "learning_rate": 1.4202407825432657e-05,
      "loss": 3.4672,
      "step": 5710
    },
    {
      "epoch": 2.1519939804364183,
      "grad_norm": 1.2038241624832153,
      "learning_rate": 1.4139704038123901e-05,
      "loss": 3.5042,
      "step": 5720
    },
    {
      "epoch": 2.1557562076749437,
      "grad_norm": 1.121882438659668,
      "learning_rate": 1.407700025081515e-05,
      "loss": 3.4732,
      "step": 5730
    },
    {
      "epoch": 2.1595184349134686,
      "grad_norm": 1.1874920129776,
      "learning_rate": 1.4014296463506396e-05,
      "loss": 3.4358,
      "step": 5740
    },
    {
      "epoch": 2.163280662151994,
      "grad_norm": 1.3526860475540161,
      "learning_rate": 1.3951592676197642e-05,
      "loss": 3.4666,
      "step": 5750
    },
    {
      "epoch": 2.1670428893905194,
      "grad_norm": 1.6199170351028442,
      "learning_rate": 1.388888888888889e-05,
      "loss": 3.4738,
      "step": 5760
    },
    {
      "epoch": 2.1708051166290443,
      "grad_norm": 1.1180750131607056,
      "learning_rate": 1.3826185101580135e-05,
      "loss": 3.4337,
      "step": 5770
    },
    {
      "epoch": 2.1745673438675697,
      "grad_norm": 1.067538857460022,
      "learning_rate": 1.3763481314271381e-05,
      "loss": 3.4572,
      "step": 5780
    },
    {
      "epoch": 2.1783295711060946,
      "grad_norm": 1.3694429397583008,
      "learning_rate": 1.370077752696263e-05,
      "loss": 3.4523,
      "step": 5790
    },
    {
      "epoch": 2.18209179834462,
      "grad_norm": 1.2441539764404297,
      "learning_rate": 1.3638073739653876e-05,
      "loss": 3.4869,
      "step": 5800
    },
    {
      "epoch": 2.1858540255831453,
      "grad_norm": 1.0890474319458008,
      "learning_rate": 1.3575369952345122e-05,
      "loss": 3.508,
      "step": 5810
    },
    {
      "epoch": 2.1896162528216703,
      "grad_norm": 1.413967490196228,
      "learning_rate": 1.351266616503637e-05,
      "loss": 3.5929,
      "step": 5820
    },
    {
      "epoch": 2.1933784800601956,
      "grad_norm": 1.2557628154754639,
      "learning_rate": 1.3449962377727615e-05,
      "loss": 3.4715,
      "step": 5830
    },
    {
      "epoch": 2.197140707298721,
      "grad_norm": 1.398942470550537,
      "learning_rate": 1.338725859041886e-05,
      "loss": 3.4968,
      "step": 5840
    },
    {
      "epoch": 2.200902934537246,
      "grad_norm": 1.1000224351882935,
      "learning_rate": 1.332455480311011e-05,
      "loss": 3.4721,
      "step": 5850
    },
    {
      "epoch": 2.2046651617757713,
      "grad_norm": 1.026434302330017,
      "learning_rate": 1.3261851015801354e-05,
      "loss": 3.4669,
      "step": 5860
    },
    {
      "epoch": 2.2084273890142967,
      "grad_norm": 1.1280220746994019,
      "learning_rate": 1.31991472284926e-05,
      "loss": 3.4108,
      "step": 5870
    },
    {
      "epoch": 2.2121896162528216,
      "grad_norm": 1.1862244606018066,
      "learning_rate": 1.3136443441183849e-05,
      "loss": 3.4375,
      "step": 5880
    },
    {
      "epoch": 2.215951843491347,
      "grad_norm": 1.1295526027679443,
      "learning_rate": 1.3073739653875095e-05,
      "loss": 3.4367,
      "step": 5890
    },
    {
      "epoch": 2.219714070729872,
      "grad_norm": 1.356905460357666,
      "learning_rate": 1.301103586656634e-05,
      "loss": 3.5786,
      "step": 5900
    },
    {
      "epoch": 2.2234762979683973,
      "grad_norm": 1.2286791801452637,
      "learning_rate": 1.2948332079257588e-05,
      "loss": 3.4277,
      "step": 5910
    },
    {
      "epoch": 2.2272385252069227,
      "grad_norm": 1.147389531135559,
      "learning_rate": 1.2885628291948834e-05,
      "loss": 3.4801,
      "step": 5920
    },
    {
      "epoch": 2.2310007524454476,
      "grad_norm": 1.2404214143753052,
      "learning_rate": 1.282292450464008e-05,
      "loss": 3.4995,
      "step": 5930
    },
    {
      "epoch": 2.234762979683973,
      "grad_norm": 1.343306303024292,
      "learning_rate": 1.2760220717331329e-05,
      "loss": 3.5107,
      "step": 5940
    },
    {
      "epoch": 2.238525206922498,
      "grad_norm": 1.0864479541778564,
      "learning_rate": 1.2697516930022574e-05,
      "loss": 3.5013,
      "step": 5950
    },
    {
      "epoch": 2.2422874341610233,
      "grad_norm": 1.185234785079956,
      "learning_rate": 1.263481314271382e-05,
      "loss": 3.5021,
      "step": 5960
    },
    {
      "epoch": 2.2460496613995486,
      "grad_norm": 1.1331162452697754,
      "learning_rate": 1.2572109355405068e-05,
      "loss": 3.5614,
      "step": 5970
    },
    {
      "epoch": 2.2498118886380736,
      "grad_norm": 1.1516467332839966,
      "learning_rate": 1.2509405568096313e-05,
      "loss": 3.4006,
      "step": 5980
    },
    {
      "epoch": 2.253574115876599,
      "grad_norm": 1.134526014328003,
      "learning_rate": 1.2446701780787561e-05,
      "loss": 3.4604,
      "step": 5990
    },
    {
      "epoch": 2.2573363431151243,
      "grad_norm": 1.2415810823440552,
      "learning_rate": 1.2383997993478807e-05,
      "loss": 3.4912,
      "step": 6000
    },
    {
      "epoch": 2.2610985703536493,
      "grad_norm": 1.2485682964324951,
      "learning_rate": 1.2321294206170052e-05,
      "loss": 3.4859,
      "step": 6010
    },
    {
      "epoch": 2.2648607975921746,
      "grad_norm": 1.064864993095398,
      "learning_rate": 1.22585904188613e-05,
      "loss": 3.4291,
      "step": 6020
    },
    {
      "epoch": 2.2686230248307,
      "grad_norm": 1.1747342348098755,
      "learning_rate": 1.2195886631552546e-05,
      "loss": 3.484,
      "step": 6030
    },
    {
      "epoch": 2.272385252069225,
      "grad_norm": 1.1811851263046265,
      "learning_rate": 1.2133182844243793e-05,
      "loss": 3.4774,
      "step": 6040
    },
    {
      "epoch": 2.2761474793077503,
      "grad_norm": 1.2067503929138184,
      "learning_rate": 1.207047905693504e-05,
      "loss": 3.458,
      "step": 6050
    },
    {
      "epoch": 2.2799097065462752,
      "grad_norm": 1.2538059949874878,
      "learning_rate": 1.2007775269626285e-05,
      "loss": 3.4979,
      "step": 6060
    },
    {
      "epoch": 2.2836719337848006,
      "grad_norm": 1.0809565782546997,
      "learning_rate": 1.1945071482317532e-05,
      "loss": 3.5361,
      "step": 6070
    },
    {
      "epoch": 2.287434161023326,
      "grad_norm": 1.1125625371932983,
      "learning_rate": 1.188236769500878e-05,
      "loss": 3.393,
      "step": 6080
    },
    {
      "epoch": 2.291196388261851,
      "grad_norm": 1.3028212785720825,
      "learning_rate": 1.1819663907700025e-05,
      "loss": 3.5076,
      "step": 6090
    },
    {
      "epoch": 2.2949586155003763,
      "grad_norm": 1.183083415031433,
      "learning_rate": 1.1756960120391273e-05,
      "loss": 3.4818,
      "step": 6100
    },
    {
      "epoch": 2.298720842738901,
      "grad_norm": 1.1765146255493164,
      "learning_rate": 1.1694256333082519e-05,
      "loss": 3.4446,
      "step": 6110
    },
    {
      "epoch": 2.3024830699774266,
      "grad_norm": 1.1913530826568604,
      "learning_rate": 1.1631552545773764e-05,
      "loss": 3.3961,
      "step": 6120
    },
    {
      "epoch": 2.306245297215952,
      "grad_norm": 1.5883889198303223,
      "learning_rate": 1.1568848758465012e-05,
      "loss": 3.5552,
      "step": 6130
    },
    {
      "epoch": 2.310007524454477,
      "grad_norm": 1.3242748975753784,
      "learning_rate": 1.150614497115626e-05,
      "loss": 3.3912,
      "step": 6140
    },
    {
      "epoch": 2.3137697516930023,
      "grad_norm": 1.4772779941558838,
      "learning_rate": 1.1443441183847505e-05,
      "loss": 3.5394,
      "step": 6150
    },
    {
      "epoch": 2.3175319789315276,
      "grad_norm": 1.181747555732727,
      "learning_rate": 1.1380737396538751e-05,
      "loss": 3.4706,
      "step": 6160
    },
    {
      "epoch": 2.3212942061700526,
      "grad_norm": 1.1332380771636963,
      "learning_rate": 1.1318033609229998e-05,
      "loss": 3.4659,
      "step": 6170
    },
    {
      "epoch": 2.325056433408578,
      "grad_norm": 1.3081555366516113,
      "learning_rate": 1.1255329821921244e-05,
      "loss": 3.4665,
      "step": 6180
    },
    {
      "epoch": 2.3288186606471033,
      "grad_norm": 1.1073168516159058,
      "learning_rate": 1.1192626034612492e-05,
      "loss": 3.4102,
      "step": 6190
    },
    {
      "epoch": 2.3325808878856282,
      "grad_norm": 1.1647123098373413,
      "learning_rate": 1.1129922247303737e-05,
      "loss": 3.4211,
      "step": 6200
    },
    {
      "epoch": 2.3363431151241536,
      "grad_norm": 1.2215454578399658,
      "learning_rate": 1.1067218459994983e-05,
      "loss": 3.4173,
      "step": 6210
    },
    {
      "epoch": 2.3401053423626785,
      "grad_norm": 1.260237216949463,
      "learning_rate": 1.100451467268623e-05,
      "loss": 3.4906,
      "step": 6220
    },
    {
      "epoch": 2.343867569601204,
      "grad_norm": 1.0600980520248413,
      "learning_rate": 1.0941810885377478e-05,
      "loss": 3.4225,
      "step": 6230
    },
    {
      "epoch": 2.3476297968397293,
      "grad_norm": 1.2340441942214966,
      "learning_rate": 1.0879107098068724e-05,
      "loss": 3.4633,
      "step": 6240
    },
    {
      "epoch": 2.351392024078254,
      "grad_norm": 1.517869472503662,
      "learning_rate": 1.081640331075997e-05,
      "loss": 3.498,
      "step": 6250
    },
    {
      "epoch": 2.3551542513167796,
      "grad_norm": 1.218021273612976,
      "learning_rate": 1.0753699523451217e-05,
      "loss": 3.4989,
      "step": 6260
    },
    {
      "epoch": 2.3589164785553045,
      "grad_norm": 1.1809413433074951,
      "learning_rate": 1.0690995736142463e-05,
      "loss": 3.4463,
      "step": 6270
    },
    {
      "epoch": 2.36267870579383,
      "grad_norm": 1.1482561826705933,
      "learning_rate": 1.062829194883371e-05,
      "loss": 3.4063,
      "step": 6280
    },
    {
      "epoch": 2.3664409330323553,
      "grad_norm": 1.3961732387542725,
      "learning_rate": 1.0565588161524958e-05,
      "loss": 3.4049,
      "step": 6290
    },
    {
      "epoch": 2.37020316027088,
      "grad_norm": 1.1941190958023071,
      "learning_rate": 1.0502884374216204e-05,
      "loss": 3.4823,
      "step": 6300
    },
    {
      "epoch": 2.3739653875094056,
      "grad_norm": 1.5802454948425293,
      "learning_rate": 1.044018058690745e-05,
      "loss": 3.5323,
      "step": 6310
    },
    {
      "epoch": 2.377727614747931,
      "grad_norm": 1.0897475481033325,
      "learning_rate": 1.0377476799598697e-05,
      "loss": 3.4338,
      "step": 6320
    },
    {
      "epoch": 2.381489841986456,
      "grad_norm": 1.3816231489181519,
      "learning_rate": 1.0314773012289943e-05,
      "loss": 3.4627,
      "step": 6330
    },
    {
      "epoch": 2.3852520692249812,
      "grad_norm": 1.0179401636123657,
      "learning_rate": 1.025206922498119e-05,
      "loss": 3.3549,
      "step": 6340
    },
    {
      "epoch": 2.3890142964635066,
      "grad_norm": 1.1292070150375366,
      "learning_rate": 1.0189365437672436e-05,
      "loss": 3.4439,
      "step": 6350
    },
    {
      "epoch": 2.3927765237020315,
      "grad_norm": 1.4284698963165283,
      "learning_rate": 1.0126661650363682e-05,
      "loss": 3.5019,
      "step": 6360
    },
    {
      "epoch": 2.396538750940557,
      "grad_norm": 1.0894728899002075,
      "learning_rate": 1.0063957863054929e-05,
      "loss": 3.4465,
      "step": 6370
    },
    {
      "epoch": 2.400300978179082,
      "grad_norm": 1.0178250074386597,
      "learning_rate": 1.0001254075746177e-05,
      "loss": 3.5036,
      "step": 6380
    },
    {
      "epoch": 2.404063205417607,
      "grad_norm": 1.1640361547470093,
      "learning_rate": 9.938550288437422e-06,
      "loss": 3.5038,
      "step": 6390
    },
    {
      "epoch": 2.4078254326561326,
      "grad_norm": 1.1307828426361084,
      "learning_rate": 9.875846501128668e-06,
      "loss": 3.533,
      "step": 6400
    },
    {
      "epoch": 2.4115876598946575,
      "grad_norm": 1.2108696699142456,
      "learning_rate": 9.813142713819916e-06,
      "loss": 3.4473,
      "step": 6410
    },
    {
      "epoch": 2.415349887133183,
      "grad_norm": 1.075972557067871,
      "learning_rate": 9.750438926511161e-06,
      "loss": 3.5137,
      "step": 6420
    },
    {
      "epoch": 2.419112114371708,
      "grad_norm": 1.2066446542739868,
      "learning_rate": 9.687735139202409e-06,
      "loss": 3.5327,
      "step": 6430
    },
    {
      "epoch": 2.422874341610233,
      "grad_norm": 1.0490467548370361,
      "learning_rate": 9.625031351893656e-06,
      "loss": 3.4349,
      "step": 6440
    },
    {
      "epoch": 2.4266365688487586,
      "grad_norm": 1.0699275732040405,
      "learning_rate": 9.5623275645849e-06,
      "loss": 3.4039,
      "step": 6450
    },
    {
      "epoch": 2.4303987960872835,
      "grad_norm": 1.4291467666625977,
      "learning_rate": 9.499623777276148e-06,
      "loss": 3.4684,
      "step": 6460
    },
    {
      "epoch": 2.434161023325809,
      "grad_norm": 1.1049844026565552,
      "learning_rate": 9.436919989967394e-06,
      "loss": 3.4313,
      "step": 6470
    },
    {
      "epoch": 2.4379232505643342,
      "grad_norm": 1.2840243577957153,
      "learning_rate": 9.374216202658641e-06,
      "loss": 3.5028,
      "step": 6480
    },
    {
      "epoch": 2.441685477802859,
      "grad_norm": 1.0823612213134766,
      "learning_rate": 9.311512415349889e-06,
      "loss": 3.538,
      "step": 6490
    },
    {
      "epoch": 2.4454477050413845,
      "grad_norm": 1.001724362373352,
      "learning_rate": 9.248808628041134e-06,
      "loss": 3.4554,
      "step": 6500
    },
    {
      "epoch": 2.44920993227991,
      "grad_norm": 1.165243148803711,
      "learning_rate": 9.18610484073238e-06,
      "loss": 3.4681,
      "step": 6510
    },
    {
      "epoch": 2.452972159518435,
      "grad_norm": 1.2048585414886475,
      "learning_rate": 9.123401053423628e-06,
      "loss": 3.5529,
      "step": 6520
    },
    {
      "epoch": 2.45673438675696,
      "grad_norm": 1.1685596704483032,
      "learning_rate": 9.060697266114873e-06,
      "loss": 3.4414,
      "step": 6530
    },
    {
      "epoch": 2.460496613995485,
      "grad_norm": 1.1246525049209595,
      "learning_rate": 8.99799347880612e-06,
      "loss": 3.4316,
      "step": 6540
    },
    {
      "epoch": 2.4642588412340105,
      "grad_norm": 1.0326309204101562,
      "learning_rate": 8.935289691497367e-06,
      "loss": 3.531,
      "step": 6550
    },
    {
      "epoch": 2.468021068472536,
      "grad_norm": 1.133095145225525,
      "learning_rate": 8.872585904188612e-06,
      "loss": 3.4603,
      "step": 6560
    },
    {
      "epoch": 2.471783295711061,
      "grad_norm": 1.5393000841140747,
      "learning_rate": 8.80988211687986e-06,
      "loss": 3.4245,
      "step": 6570
    },
    {
      "epoch": 2.475545522949586,
      "grad_norm": 1.2813609838485718,
      "learning_rate": 8.747178329571107e-06,
      "loss": 3.4115,
      "step": 6580
    },
    {
      "epoch": 2.479307750188111,
      "grad_norm": 1.4001842737197876,
      "learning_rate": 8.684474542262353e-06,
      "loss": 3.4877,
      "step": 6590
    },
    {
      "epoch": 2.4830699774266365,
      "grad_norm": 1.2713654041290283,
      "learning_rate": 8.621770754953599e-06,
      "loss": 3.4617,
      "step": 6600
    },
    {
      "epoch": 2.486832204665162,
      "grad_norm": 1.3312656879425049,
      "learning_rate": 8.559066967644846e-06,
      "loss": 3.509,
      "step": 6610
    },
    {
      "epoch": 2.490594431903687,
      "grad_norm": 1.535139799118042,
      "learning_rate": 8.496363180336092e-06,
      "loss": 3.4397,
      "step": 6620
    },
    {
      "epoch": 2.494356659142212,
      "grad_norm": 1.3016728162765503,
      "learning_rate": 8.43365939302734e-06,
      "loss": 3.4903,
      "step": 6630
    },
    {
      "epoch": 2.4981188863807375,
      "grad_norm": 1.6945139169692993,
      "learning_rate": 8.370955605718587e-06,
      "loss": 3.5276,
      "step": 6640
    },
    {
      "epoch": 2.5018811136192625,
      "grad_norm": 1.2777961492538452,
      "learning_rate": 8.308251818409831e-06,
      "loss": 3.4585,
      "step": 6650
    },
    {
      "epoch": 2.505643340857788,
      "grad_norm": 1.2819397449493408,
      "learning_rate": 8.245548031101078e-06,
      "loss": 3.494,
      "step": 6660
    },
    {
      "epoch": 2.509405568096313,
      "grad_norm": 1.1014679670333862,
      "learning_rate": 8.182844243792326e-06,
      "loss": 3.4526,
      "step": 6670
    },
    {
      "epoch": 2.513167795334838,
      "grad_norm": 1.2842036485671997,
      "learning_rate": 8.120140456483572e-06,
      "loss": 3.4564,
      "step": 6680
    },
    {
      "epoch": 2.5169300225733635,
      "grad_norm": 1.4288996458053589,
      "learning_rate": 8.05743666917482e-06,
      "loss": 3.4609,
      "step": 6690
    },
    {
      "epoch": 2.520692249811889,
      "grad_norm": 1.1332257986068726,
      "learning_rate": 7.994732881866065e-06,
      "loss": 3.4251,
      "step": 6700
    },
    {
      "epoch": 2.524454477050414,
      "grad_norm": 1.3046948909759521,
      "learning_rate": 7.93202909455731e-06,
      "loss": 3.5004,
      "step": 6710
    },
    {
      "epoch": 2.528216704288939,
      "grad_norm": 1.2279467582702637,
      "learning_rate": 7.869325307248558e-06,
      "loss": 3.4746,
      "step": 6720
    },
    {
      "epoch": 2.531978931527464,
      "grad_norm": 1.296160101890564,
      "learning_rate": 7.806621519939806e-06,
      "loss": 3.4157,
      "step": 6730
    },
    {
      "epoch": 2.5357411587659895,
      "grad_norm": 1.3706555366516113,
      "learning_rate": 7.743917732631051e-06,
      "loss": 3.4644,
      "step": 6740
    },
    {
      "epoch": 2.5395033860045144,
      "grad_norm": 1.3851714134216309,
      "learning_rate": 7.681213945322297e-06,
      "loss": 3.5044,
      "step": 6750
    },
    {
      "epoch": 2.54326561324304,
      "grad_norm": 1.2287774085998535,
      "learning_rate": 7.618510158013545e-06,
      "loss": 3.4856,
      "step": 6760
    },
    {
      "epoch": 2.547027840481565,
      "grad_norm": 1.1458841562271118,
      "learning_rate": 7.5558063707047905e-06,
      "loss": 3.517,
      "step": 6770
    },
    {
      "epoch": 2.55079006772009,
      "grad_norm": 1.2859842777252197,
      "learning_rate": 7.493102583396037e-06,
      "loss": 3.4986,
      "step": 6780
    },
    {
      "epoch": 2.5545522949586155,
      "grad_norm": 1.0990946292877197,
      "learning_rate": 7.4303987960872845e-06,
      "loss": 3.5258,
      "step": 6790
    },
    {
      "epoch": 2.558314522197141,
      "grad_norm": 1.1020588874816895,
      "learning_rate": 7.36769500877853e-06,
      "loss": 3.4261,
      "step": 6800
    },
    {
      "epoch": 2.5620767494356658,
      "grad_norm": 1.3432327508926392,
      "learning_rate": 7.304991221469777e-06,
      "loss": 3.4673,
      "step": 6810
    },
    {
      "epoch": 2.565838976674191,
      "grad_norm": 1.2535035610198975,
      "learning_rate": 7.242287434161024e-06,
      "loss": 3.3973,
      "step": 6820
    },
    {
      "epoch": 2.5696012039127165,
      "grad_norm": 1.2334809303283691,
      "learning_rate": 7.17958364685227e-06,
      "loss": 3.4196,
      "step": 6830
    },
    {
      "epoch": 2.5733634311512414,
      "grad_norm": 1.3782025575637817,
      "learning_rate": 7.116879859543517e-06,
      "loss": 3.5212,
      "step": 6840
    },
    {
      "epoch": 2.577125658389767,
      "grad_norm": 1.3218199014663696,
      "learning_rate": 7.054176072234764e-06,
      "loss": 3.4176,
      "step": 6850
    },
    {
      "epoch": 2.580887885628292,
      "grad_norm": 1.1813604831695557,
      "learning_rate": 6.991472284926009e-06,
      "loss": 3.4857,
      "step": 6860
    },
    {
      "epoch": 2.584650112866817,
      "grad_norm": 1.290177583694458,
      "learning_rate": 6.928768497617257e-06,
      "loss": 3.4858,
      "step": 6870
    },
    {
      "epoch": 2.5884123401053425,
      "grad_norm": 1.1733911037445068,
      "learning_rate": 6.866064710308503e-06,
      "loss": 3.4238,
      "step": 6880
    },
    {
      "epoch": 2.5921745673438674,
      "grad_norm": 1.2812148332595825,
      "learning_rate": 6.803360922999749e-06,
      "loss": 3.4695,
      "step": 6890
    },
    {
      "epoch": 2.595936794582393,
      "grad_norm": 1.1598063707351685,
      "learning_rate": 6.7406571356909965e-06,
      "loss": 3.5395,
      "step": 6900
    },
    {
      "epoch": 2.5996990218209177,
      "grad_norm": 1.2932274341583252,
      "learning_rate": 6.677953348382243e-06,
      "loss": 3.5188,
      "step": 6910
    },
    {
      "epoch": 2.603461249059443,
      "grad_norm": 1.0654048919677734,
      "learning_rate": 6.615249561073489e-06,
      "loss": 3.4632,
      "step": 6920
    },
    {
      "epoch": 2.6072234762979685,
      "grad_norm": 1.2396485805511475,
      "learning_rate": 6.5525457737647355e-06,
      "loss": 3.4209,
      "step": 6930
    },
    {
      "epoch": 2.6109857035364934,
      "grad_norm": 1.750327467918396,
      "learning_rate": 6.489841986455983e-06,
      "loss": 3.4888,
      "step": 6940
    },
    {
      "epoch": 2.6147479307750188,
      "grad_norm": 1.2243051528930664,
      "learning_rate": 6.427138199147229e-06,
      "loss": 3.4905,
      "step": 6950
    },
    {
      "epoch": 2.618510158013544,
      "grad_norm": 1.366956114768982,
      "learning_rate": 6.364434411838475e-06,
      "loss": 3.4089,
      "step": 6960
    },
    {
      "epoch": 2.622272385252069,
      "grad_norm": 1.2815353870391846,
      "learning_rate": 6.301730624529723e-06,
      "loss": 3.4806,
      "step": 6970
    },
    {
      "epoch": 2.6260346124905944,
      "grad_norm": 1.168515920639038,
      "learning_rate": 6.239026837220968e-06,
      "loss": 3.5073,
      "step": 6980
    },
    {
      "epoch": 2.62979683972912,
      "grad_norm": 1.200411319732666,
      "learning_rate": 6.176323049912215e-06,
      "loss": 3.4972,
      "step": 6990
    },
    {
      "epoch": 2.6335590669676447,
      "grad_norm": 1.104385256767273,
      "learning_rate": 6.113619262603462e-06,
      "loss": 3.4482,
      "step": 7000
    },
    {
      "epoch": 2.63732129420617,
      "grad_norm": 1.218826174736023,
      "learning_rate": 6.050915475294708e-06,
      "loss": 3.4725,
      "step": 7010
    },
    {
      "epoch": 2.6410835214446955,
      "grad_norm": 1.5948418378829956,
      "learning_rate": 5.988211687985955e-06,
      "loss": 3.4394,
      "step": 7020
    },
    {
      "epoch": 2.6448457486832204,
      "grad_norm": 1.2479844093322754,
      "learning_rate": 5.925507900677201e-06,
      "loss": 3.5141,
      "step": 7030
    },
    {
      "epoch": 2.648607975921746,
      "grad_norm": 1.0851616859436035,
      "learning_rate": 5.8628041133684475e-06,
      "loss": 3.4304,
      "step": 7040
    },
    {
      "epoch": 2.6523702031602707,
      "grad_norm": 1.3495240211486816,
      "learning_rate": 5.800100326059694e-06,
      "loss": 3.4379,
      "step": 7050
    },
    {
      "epoch": 2.656132430398796,
      "grad_norm": 1.354783296585083,
      "learning_rate": 5.737396538750941e-06,
      "loss": 3.5198,
      "step": 7060
    },
    {
      "epoch": 2.659894657637321,
      "grad_norm": 1.140820860862732,
      "learning_rate": 5.674692751442187e-06,
      "loss": 3.4176,
      "step": 7070
    },
    {
      "epoch": 2.6636568848758464,
      "grad_norm": 1.2425206899642944,
      "learning_rate": 5.611988964133434e-06,
      "loss": 3.4313,
      "step": 7080
    },
    {
      "epoch": 2.6674191121143718,
      "grad_norm": 1.1841131448745728,
      "learning_rate": 5.5492851768246806e-06,
      "loss": 3.4414,
      "step": 7090
    },
    {
      "epoch": 2.6711813393528967,
      "grad_norm": 1.0608471632003784,
      "learning_rate": 5.486581389515927e-06,
      "loss": 3.3919,
      "step": 7100
    },
    {
      "epoch": 2.674943566591422,
      "grad_norm": 1.264012336730957,
      "learning_rate": 5.423877602207174e-06,
      "loss": 3.4706,
      "step": 7110
    },
    {
      "epoch": 2.6787057938299474,
      "grad_norm": 1.1331719160079956,
      "learning_rate": 5.3611738148984204e-06,
      "loss": 3.4768,
      "step": 7120
    },
    {
      "epoch": 2.6824680210684724,
      "grad_norm": 1.2121586799621582,
      "learning_rate": 5.298470027589666e-06,
      "loss": 3.4688,
      "step": 7130
    },
    {
      "epoch": 2.6862302483069977,
      "grad_norm": 1.3385390043258667,
      "learning_rate": 5.235766240280914e-06,
      "loss": 3.4959,
      "step": 7140
    },
    {
      "epoch": 2.689992475545523,
      "grad_norm": 1.1271233558654785,
      "learning_rate": 5.1730624529721594e-06,
      "loss": 3.3903,
      "step": 7150
    },
    {
      "epoch": 2.693754702784048,
      "grad_norm": 1.231935739517212,
      "learning_rate": 5.110358665663406e-06,
      "loss": 3.4188,
      "step": 7160
    },
    {
      "epoch": 2.6975169300225734,
      "grad_norm": 0.9682213068008423,
      "learning_rate": 5.0476548783546535e-06,
      "loss": 3.4133,
      "step": 7170
    },
    {
      "epoch": 2.701279157261099,
      "grad_norm": 1.0282390117645264,
      "learning_rate": 4.984951091045899e-06,
      "loss": 3.5704,
      "step": 7180
    },
    {
      "epoch": 2.7050413844996237,
      "grad_norm": 1.2467440366744995,
      "learning_rate": 4.922247303737146e-06,
      "loss": 3.4578,
      "step": 7190
    },
    {
      "epoch": 2.708803611738149,
      "grad_norm": 1.8877460956573486,
      "learning_rate": 4.8595435164283925e-06,
      "loss": 3.4011,
      "step": 7200
    },
    {
      "epoch": 2.712565838976674,
      "grad_norm": 1.1489886045455933,
      "learning_rate": 4.796839729119639e-06,
      "loss": 3.4865,
      "step": 7210
    },
    {
      "epoch": 2.7163280662151994,
      "grad_norm": 1.5807675123214722,
      "learning_rate": 4.734135941810886e-06,
      "loss": 3.4425,
      "step": 7220
    },
    {
      "epoch": 2.7200902934537243,
      "grad_norm": 1.3291631937026978,
      "learning_rate": 4.6714321545021315e-06,
      "loss": 3.5752,
      "step": 7230
    },
    {
      "epoch": 2.7238525206922497,
      "grad_norm": 1.373357892036438,
      "learning_rate": 4.608728367193379e-06,
      "loss": 3.4722,
      "step": 7240
    },
    {
      "epoch": 2.727614747930775,
      "grad_norm": 1.2171937227249146,
      "learning_rate": 4.546024579884625e-06,
      "loss": 3.4681,
      "step": 7250
    },
    {
      "epoch": 2.7313769751693,
      "grad_norm": 1.5302900075912476,
      "learning_rate": 4.483320792575871e-06,
      "loss": 3.4903,
      "step": 7260
    },
    {
      "epoch": 2.7351392024078254,
      "grad_norm": 1.1498595476150513,
      "learning_rate": 4.420617005267119e-06,
      "loss": 3.4518,
      "step": 7270
    },
    {
      "epoch": 2.7389014296463507,
      "grad_norm": 1.5389018058776855,
      "learning_rate": 4.357913217958365e-06,
      "loss": 3.4782,
      "step": 7280
    },
    {
      "epoch": 2.7426636568848757,
      "grad_norm": 1.4061367511749268,
      "learning_rate": 4.295209430649611e-06,
      "loss": 3.4547,
      "step": 7290
    },
    {
      "epoch": 2.746425884123401,
      "grad_norm": 1.1304187774658203,
      "learning_rate": 4.232505643340858e-06,
      "loss": 3.4161,
      "step": 7300
    },
    {
      "epoch": 2.7501881113619264,
      "grad_norm": 1.2867242097854614,
      "learning_rate": 4.1698018560321045e-06,
      "loss": 3.4608,
      "step": 7310
    },
    {
      "epoch": 2.7539503386004514,
      "grad_norm": 1.5656346082687378,
      "learning_rate": 4.107098068723351e-06,
      "loss": 3.4392,
      "step": 7320
    },
    {
      "epoch": 2.7577125658389767,
      "grad_norm": 1.375110149383545,
      "learning_rate": 4.044394281414598e-06,
      "loss": 3.449,
      "step": 7330
    },
    {
      "epoch": 2.761474793077502,
      "grad_norm": 1.2946237325668335,
      "learning_rate": 3.981690494105844e-06,
      "loss": 3.5242,
      "step": 7340
    },
    {
      "epoch": 2.765237020316027,
      "grad_norm": 1.2368115186691284,
      "learning_rate": 3.91898670679709e-06,
      "loss": 3.4381,
      "step": 7350
    },
    {
      "epoch": 2.7689992475545524,
      "grad_norm": 1.0967212915420532,
      "learning_rate": 3.856282919488338e-06,
      "loss": 3.5062,
      "step": 7360
    },
    {
      "epoch": 2.7727614747930778,
      "grad_norm": 1.2326918840408325,
      "learning_rate": 3.7935791321795838e-06,
      "loss": 3.4916,
      "step": 7370
    },
    {
      "epoch": 2.7765237020316027,
      "grad_norm": 1.1433780193328857,
      "learning_rate": 3.73087534487083e-06,
      "loss": 3.4909,
      "step": 7380
    },
    {
      "epoch": 2.780285929270128,
      "grad_norm": 1.2058767080307007,
      "learning_rate": 3.668171557562077e-06,
      "loss": 3.4632,
      "step": 7390
    },
    {
      "epoch": 2.784048156508653,
      "grad_norm": 1.3142249584197998,
      "learning_rate": 3.6054677702533236e-06,
      "loss": 3.4703,
      "step": 7400
    },
    {
      "epoch": 2.7878103837471784,
      "grad_norm": 1.060783863067627,
      "learning_rate": 3.54276398294457e-06,
      "loss": 3.3769,
      "step": 7410
    },
    {
      "epoch": 2.7915726109857033,
      "grad_norm": 1.1184427738189697,
      "learning_rate": 3.480060195635817e-06,
      "loss": 3.43,
      "step": 7420
    },
    {
      "epoch": 2.7953348382242287,
      "grad_norm": 1.0541534423828125,
      "learning_rate": 3.417356408327063e-06,
      "loss": 3.3981,
      "step": 7430
    },
    {
      "epoch": 2.799097065462754,
      "grad_norm": 1.2475494146347046,
      "learning_rate": 3.3546526210183097e-06,
      "loss": 3.4203,
      "step": 7440
    },
    {
      "epoch": 2.802859292701279,
      "grad_norm": 1.1187487840652466,
      "learning_rate": 3.2919488337095563e-06,
      "loss": 3.5003,
      "step": 7450
    },
    {
      "epoch": 2.8066215199398044,
      "grad_norm": 1.2098450660705566,
      "learning_rate": 3.229245046400803e-06,
      "loss": 3.4514,
      "step": 7460
    },
    {
      "epoch": 2.8103837471783297,
      "grad_norm": 1.1842025518417358,
      "learning_rate": 3.166541259092049e-06,
      "loss": 3.4776,
      "step": 7470
    },
    {
      "epoch": 2.8141459744168547,
      "grad_norm": 1.4888311624526978,
      "learning_rate": 3.1038374717832957e-06,
      "loss": 3.6446,
      "step": 7480
    },
    {
      "epoch": 2.81790820165538,
      "grad_norm": 1.171553134918213,
      "learning_rate": 3.0411336844745424e-06,
      "loss": 3.4506,
      "step": 7490
    },
    {
      "epoch": 2.8216704288939054,
      "grad_norm": 1.1711747646331787,
      "learning_rate": 2.978429897165789e-06,
      "loss": 3.4726,
      "step": 7500
    },
    {
      "epoch": 2.8254326561324303,
      "grad_norm": 1.251444935798645,
      "learning_rate": 2.9157261098570356e-06,
      "loss": 3.5411,
      "step": 7510
    },
    {
      "epoch": 2.8291948833709557,
      "grad_norm": 2.1152846813201904,
      "learning_rate": 2.8530223225482822e-06,
      "loss": 3.4212,
      "step": 7520
    },
    {
      "epoch": 2.832957110609481,
      "grad_norm": 1.3772162199020386,
      "learning_rate": 2.7903185352395284e-06,
      "loss": 3.4296,
      "step": 7530
    },
    {
      "epoch": 2.836719337848006,
      "grad_norm": 1.3346630334854126,
      "learning_rate": 2.727614747930775e-06,
      "loss": 3.5715,
      "step": 7540
    },
    {
      "epoch": 2.8404815650865314,
      "grad_norm": 1.2253273725509644,
      "learning_rate": 2.6649109606220217e-06,
      "loss": 3.4321,
      "step": 7550
    },
    {
      "epoch": 2.8442437923250563,
      "grad_norm": 1.2939902544021606,
      "learning_rate": 2.6022071733132683e-06,
      "loss": 3.5125,
      "step": 7560
    },
    {
      "epoch": 2.8480060195635817,
      "grad_norm": 1.4771772623062134,
      "learning_rate": 2.539503386004515e-06,
      "loss": 3.5085,
      "step": 7570
    },
    {
      "epoch": 2.8517682468021066,
      "grad_norm": 1.2817808389663696,
      "learning_rate": 2.4767995986957615e-06,
      "loss": 3.4652,
      "step": 7580
    },
    {
      "epoch": 2.855530474040632,
      "grad_norm": 1.2142691612243652,
      "learning_rate": 2.4140958113870077e-06,
      "loss": 3.4793,
      "step": 7590
    },
    {
      "epoch": 2.8592927012791574,
      "grad_norm": 1.3565620183944702,
      "learning_rate": 2.3513920240782543e-06,
      "loss": 3.4552,
      "step": 7600
    },
    {
      "epoch": 2.8630549285176823,
      "grad_norm": 1.2205522060394287,
      "learning_rate": 2.288688236769501e-06,
      "loss": 3.435,
      "step": 7610
    },
    {
      "epoch": 2.8668171557562077,
      "grad_norm": 1.5175577402114868,
      "learning_rate": 2.2259844494607476e-06,
      "loss": 3.4646,
      "step": 7620
    },
    {
      "epoch": 2.870579382994733,
      "grad_norm": 1.2750755548477173,
      "learning_rate": 2.163280662151994e-06,
      "loss": 3.4317,
      "step": 7630
    },
    {
      "epoch": 2.874341610233258,
      "grad_norm": 1.1552047729492188,
      "learning_rate": 2.1005768748432404e-06,
      "loss": 3.477,
      "step": 7640
    },
    {
      "epoch": 2.8781038374717833,
      "grad_norm": 1.3016124963760376,
      "learning_rate": 2.037873087534487e-06,
      "loss": 3.4874,
      "step": 7650
    },
    {
      "epoch": 2.8818660647103087,
      "grad_norm": 1.217200517654419,
      "learning_rate": 1.975169300225734e-06,
      "loss": 3.4333,
      "step": 7660
    },
    {
      "epoch": 2.8856282919488336,
      "grad_norm": 1.3584258556365967,
      "learning_rate": 1.9124655129169802e-06,
      "loss": 3.4403,
      "step": 7670
    },
    {
      "epoch": 2.889390519187359,
      "grad_norm": 1.097968339920044,
      "learning_rate": 1.8497617256082269e-06,
      "loss": 3.4426,
      "step": 7680
    },
    {
      "epoch": 2.8931527464258844,
      "grad_norm": 1.1124645471572876,
      "learning_rate": 1.7870579382994735e-06,
      "loss": 3.4636,
      "step": 7690
    },
    {
      "epoch": 2.8969149736644093,
      "grad_norm": 1.1811805963516235,
      "learning_rate": 1.7243541509907199e-06,
      "loss": 3.4797,
      "step": 7700
    },
    {
      "epoch": 2.9006772009029347,
      "grad_norm": 1.202962040901184,
      "learning_rate": 1.6616503636819665e-06,
      "loss": 3.4829,
      "step": 7710
    },
    {
      "epoch": 2.9044394281414596,
      "grad_norm": 1.3923338651657104,
      "learning_rate": 1.5989465763732131e-06,
      "loss": 3.4821,
      "step": 7720
    },
    {
      "epoch": 2.908201655379985,
      "grad_norm": 1.1985255479812622,
      "learning_rate": 1.5362427890644595e-06,
      "loss": 3.4031,
      "step": 7730
    },
    {
      "epoch": 2.91196388261851,
      "grad_norm": 1.1400165557861328,
      "learning_rate": 1.4735390017557061e-06,
      "loss": 3.3535,
      "step": 7740
    },
    {
      "epoch": 2.9157261098570353,
      "grad_norm": 1.2023532390594482,
      "learning_rate": 1.4108352144469528e-06,
      "loss": 3.4543,
      "step": 7750
    },
    {
      "epoch": 2.9194883370955607,
      "grad_norm": 1.2273224592208862,
      "learning_rate": 1.3481314271381992e-06,
      "loss": 3.3381,
      "step": 7760
    },
    {
      "epoch": 2.9232505643340856,
      "grad_norm": 1.3586103916168213,
      "learning_rate": 1.2854276398294458e-06,
      "loss": 3.4619,
      "step": 7770
    },
    {
      "epoch": 2.927012791572611,
      "grad_norm": 1.1711581945419312,
      "learning_rate": 1.2227238525206924e-06,
      "loss": 3.4665,
      "step": 7780
    },
    {
      "epoch": 2.9307750188111363,
      "grad_norm": 1.297713041305542,
      "learning_rate": 1.1600200652119388e-06,
      "loss": 3.5683,
      "step": 7790
    },
    {
      "epoch": 2.9345372460496613,
      "grad_norm": 1.112700343132019,
      "learning_rate": 1.0973162779031852e-06,
      "loss": 3.4319,
      "step": 7800
    },
    {
      "epoch": 2.9382994732881866,
      "grad_norm": 1.4511936902999878,
      "learning_rate": 1.034612490594432e-06,
      "loss": 3.5025,
      "step": 7810
    },
    {
      "epoch": 2.942061700526712,
      "grad_norm": 1.2243735790252686,
      "learning_rate": 9.719087032856785e-07,
      "loss": 3.4141,
      "step": 7820
    },
    {
      "epoch": 2.945823927765237,
      "grad_norm": 1.2669792175292969,
      "learning_rate": 9.09204915976925e-07,
      "loss": 3.5281,
      "step": 7830
    },
    {
      "epoch": 2.9495861550037623,
      "grad_norm": 1.2227932214736938,
      "learning_rate": 8.465011286681717e-07,
      "loss": 3.4566,
      "step": 7840
    },
    {
      "epoch": 2.9533483822422877,
      "grad_norm": 1.0594056844711304,
      "learning_rate": 7.837973413594182e-07,
      "loss": 3.4588,
      "step": 7850
    },
    {
      "epoch": 2.9571106094808126,
      "grad_norm": 1.217549204826355,
      "learning_rate": 7.210935540506646e-07,
      "loss": 3.4781,
      "step": 7860
    },
    {
      "epoch": 2.960872836719338,
      "grad_norm": 1.0404196977615356,
      "learning_rate": 6.583897667419112e-07,
      "loss": 3.5393,
      "step": 7870
    },
    {
      "epoch": 2.964635063957863,
      "grad_norm": 1.2914683818817139,
      "learning_rate": 5.956859794331579e-07,
      "loss": 3.4087,
      "step": 7880
    },
    {
      "epoch": 2.9683972911963883,
      "grad_norm": 1.3161191940307617,
      "learning_rate": 5.329821921244044e-07,
      "loss": 3.5277,
      "step": 7890
    },
    {
      "epoch": 2.972159518434913,
      "grad_norm": 1.2411588430404663,
      "learning_rate": 4.7027840481565094e-07,
      "loss": 3.5546,
      "step": 7900
    },
    {
      "epoch": 2.9759217456734386,
      "grad_norm": 1.36329185962677,
      "learning_rate": 4.075746175068974e-07,
      "loss": 3.445,
      "step": 7910
    },
    {
      "epoch": 2.979683972911964,
      "grad_norm": 1.2140921354293823,
      "learning_rate": 3.44870830198144e-07,
      "loss": 3.4645,
      "step": 7920
    },
    {
      "epoch": 2.983446200150489,
      "grad_norm": 1.4051274061203003,
      "learning_rate": 2.8216704288939053e-07,
      "loss": 3.4527,
      "step": 7930
    },
    {
      "epoch": 2.9872084273890143,
      "grad_norm": 1.123199224472046,
      "learning_rate": 2.1946325558063707e-07,
      "loss": 3.5328,
      "step": 7940
    },
    {
      "epoch": 2.9909706546275396,
      "grad_norm": 1.2017155885696411,
      "learning_rate": 1.5675946827188364e-07,
      "loss": 3.4432,
      "step": 7950
    },
    {
      "epoch": 2.9947328818660646,
      "grad_norm": 1.431501030921936,
      "learning_rate": 9.405568096313018e-08,
      "loss": 3.4865,
      "step": 7960
    },
    {
      "epoch": 2.99849510910459,
      "grad_norm": 1.3069243431091309,
      "learning_rate": 3.1351893654376724e-08,
      "loss": 3.4405,
      "step": 7970
    }
  ],
  "logging_steps": 10,
  "max_steps": 7974,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8363067461074944.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
